---
title: "Analysis for Revision 2"
author: "Alice MacQueen"
format: 
  html:
    code-fold: true
    code-annotations: hover
    execute: 
      echo: false
      cache: true
editor: visual
toc: true
number-sections: true
---

::: callout-important
## Analysis Version 1.2

As of 2024-02-07, this file was a copy of the Rmd file of the same name. After 2024-02-07, this Quarto document will be modified and kept up to date for this analysis version.
:::

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(bigsnpr)
library(mashr)
library(switchgrassGWAS)
library(rlist)
library(cowplot)
library(here)
library(zoo)
library(rrBLUP)
```

::: callout-tip
## Install reminders for reinstalls

On debian: `apt install libgsl-dev` to install the GNU Scientific Library, zB.

For mashr: Sometimes install.packages("RcppGSL") is also needed.
:::

## Overview

Sam developed a greedy mash algorithm to find the best set of covariance matrices to include. Alice used this algorithm on 19K randomly associated variants using a large set of covariance matrices with h\^2 on their diagonals.

Then, Alice used the best set of covariance matrices on 19K strongly associated variants.

Outline of the current analysis:

1.  Set up. Look at phenotype distribution & heritability; run GWAS to get univariate SNP effect estimates & standard errors. Done elsewhere.

2.  Make hypothesis covariance matrices based on weather data from 2018 - 2020. For cumulative weather variables, use a range of days: every day for the first week, and every week until 28 days. Come back and add more if 28 is chosen by greedy mash.

3.  Run greedy mash to find best set of covariance matrices that explain SNP effect variation across environments, using 19K 'randomly associated variants'. Go back to (1) if high number of day covar matrices tend to be chosen by greedy mash.

4.  Use covariances from (3) to run mash on 19K 'strongly associated variants'.

5.  Look at loadings on covariance matrices and meanings of covariance matrices as the writeup (Figure 2, 3; Table 1). Look at amount of antagonistic pleiotropy vs same sign significant effects.

6.  Have Li repeat the QTL analysis and incorporate her results.

------------------------------------------------------------------------

## Step 1: GWAS

## Step 2: Covariance matrices

### Generate weather variables

### Covar 1-28d weather

As of 2023-09-11, want to remake these per reviewer revision to have h\^2 on the diagonal instead of the CV. Estimate h\^2 for these new covar matrices using rrBLUP.

### load phe & wea data

```{r}
#| eval: false

phe_ten_sites <- readRDS(here("data", "Phenotypes_2018_to_2021_10_sites.rds"))
sites <- readRDS("~/Github/pvdiv-phenology-gxe/data/sites.rds")
jday_phe <- readRDS("~/Github/pvdiv-phenology-gxe/data/Julian_date_GDD_and_rainfall_phenotypes_4wcr_and_gwas.rds")
wea_ten_sites <- readRDS(file = here("data", "Daily_weather_2018_to_2021_10_sites.rds"))

##function to calculate daylength

day.length.hrs <- function(day, latitude) {

  daylength.coeff <- asin(0.39795*cos(0.2163108 + 2*atan(0.9671396*tan(0.00860*(day - 186)))))

  daylength.hrs <- 24 - (24/pi)*acos((sin(0.8333*pi/180) + sin(latitude*pi/180)*sin(daylength.coeff))/(cos(latitude*pi/180)*cos(daylength.coeff)))

  return(daylength.hrs)

}

phe_2019 <- jday_phe %>%
  select(-(CGDD_12C:dyln_change_sec)) %>%
  pivot_longer(cols = GR50:FL50, names_to = "PHE", values_to = "JDAY")
```

```{r}
#| eval: false
#| 
wea_ten_sites <- wea_ten_sites %>%
  mutate(JDAY = yday(Working_date),
         DYLN = day.length.hrs(day = JDAY, latitude = Latitude),
         tmax_sm = ifelse(is.na(tmax),
                          (na.locf(tmax) + na.locf(tmax, fromLast = TRUE))/2,
                          tmax),
         tmin_sm = ifelse(is.na(tmin),
                          (na.locf(tmin) + na.locf(tmin, fromLast = TRUE))/2,
                          tmin),
         tmean_sm = ifelse(is.na(Tmean),
                          (na.locf(Tmean) + na.locf(Tmean, fromLast = TRUE))/2,
                          Tmean),
         GDD_12Cbase = ifelse((tmax_sm + tmin_sm)/2 >= 12.0,
                              (tmax_sm + tmin_sm)/2 - 10,
                              0),
         Year = year(Working_date)) %>%
  mutate(JDAY_EXP = case_when(Year == 2018 ~ JDAY,
                              Year == 2019 ~ JDAY + 365,
                              Year == 2020 ~ JDAY + (365*2),
                              Year == 2021 ~ JDAY + (365*3),
                              TRUE ~ NA_real_)) %>%
  arrange(Latitude, Year, JDAY_EXP) %>%
  select(-JDAY) %>%
  group_by(manu_site) %>%
  mutate(crain_2d = prcp + lag(prcp, default = 0),
         crain_3d = prcp + lag(prcp, default = 0) + 
           lag(prcp, default = 0, n = 2),
         crain_4d = prcp + lag(prcp, default = 0) + 
           lag(prcp, default = 0, n = 2) + 
           lag(prcp, default = 0, n = 3),
         crain_5d = prcp + lag(prcp, default = 0) + 
           lag(prcp, default = 0, n = 2) + lag(prcp, default = 0, n = 3) +
           lag(prcp, default = 0, n = 4),
         crain_6d = prcp + lag(prcp, default = 0) + 
           lag(prcp, default = 0, n = 2) + lag(prcp, default = 0, n = 3) +
           lag(prcp, default = 0, n = 4) +
           lag(prcp, default = 0, n = 5),
         crain_7d = prcp + lag(prcp, default = 0) + 
           lag(prcp, default = 0, n = 2) + lag(prcp, default = 0, n = 3) +
           lag(prcp, default = 0, n = 4) +
           lag(prcp, default = 0, n = 5) +
           lag(prcp, default = 0, n = 6),
         dyln_change_sec = (DYLN - lag(DYLN))*60*60,
         dyln_change_sec_2d_prior = (lag(DYLN, n = 1) - 
                                       lag(DYLN, n = 2))*60*60,
         dyln_change_sec_3d_prior = (lag(DYLN, n = 2) - 
                                       lag(DYLN, n = 3))*60*60,
         dyln_change_sec_4d_prior = (lag(DYLN, n = 3) - 
                                       lag(DYLN, n = 4))*60*60,
         dyln_change_sec_5d_prior = (lag(DYLN, n = 4) - 
                                       lag(DYLN, n = 5))*60*60,
         dyln_change_sec_6d_prior = (lag(DYLN, n = 5) - 
                                       lag(DYLN, n = 6))*60*60,
         dyln_change_sec_7d_prior = (lag(DYLN, n = 6) - 
                                       lag(DYLN, n = 7))*60*60,
         dyln_change_sec_14d_prior = (lag(DYLN, n = 13) - 
                                       lag(DYLN, n = 14))*60*60,
         dyln_2d_prior = lag(DYLN, n = 1),
         dyln_3d_prior = lag(DYLN, n = 2),
         dyln_4d_prior = lag(DYLN, n = 3),
         dyln_5d_prior = lag(DYLN, n = 4),
         dyln_6d_prior = lag(DYLN, n = 5),
         dyln_7d_prior = lag(DYLN, n = 6),
         dyln_14d_prior = lag(DYLN, n = 13),
         cgdd_12c_2d = (GDD_12Cbase + lag(GDD_12Cbase, default = 0))/2,
         tave_2d = (tmean_sm + lag(tmean_sm, default = 0))/2,
         cgdd_12c_3d = (GDD_12Cbase + lag(GDD_12Cbase, default = 0) + 
           lag(GDD_12Cbase, default = 0, n = 2))/3,
         tave_3d = (tmean_sm + lag(tmean_sm, default = 0) + 
           lag(tmean_sm, default = 0, n = 2))/3,
         cgdd_12c_4d = (GDD_12Cbase + lag(GDD_12Cbase, default = 0) + 
           lag(GDD_12Cbase, default = 0, n = 2) + 
           lag(GDD_12Cbase, default = 0, n = 3))/4,
         tave_4d = (tmean_sm + lag(tmean_sm, default = 0) + 
           lag(tmean_sm, default = 0, n = 2) + 
           lag(tmean_sm, default = 0, n = 3))/4,
         cgdd_12c_5d = (GDD_12Cbase + lag(GDD_12Cbase, default = 0) + 
           lag(GDD_12Cbase, default = 0, n = 2) + 
           lag(GDD_12Cbase, default = 0, n = 3) +
           lag(GDD_12Cbase, default = 0, n = 4))/5,
         tave_5d = (tmean_sm + lag(tmean_sm, default = 0) + 
           lag(tmean_sm, default = 0, n = 2) + 
           lag(tmean_sm, default = 0, n = 3) +
           lag(tmean_sm, default = 0, n = 4))/5,
         cgdd_12c_6d = (GDD_12Cbase + lag(GDD_12Cbase, default = 0) + 
           lag(GDD_12Cbase, default = 0, n = 2) + 
           lag(GDD_12Cbase, default = 0, n = 3) +
           lag(GDD_12Cbase, default = 0, n = 4) +
           lag(GDD_12Cbase, default = 0, n = 5))/6,
         tave_6d = (tmean_sm + lag(tmean_sm, default = 0) + 
           lag(tmean_sm, default = 0, n = 2) + 
           lag(tmean_sm, default = 0, n = 3) +
           lag(tmean_sm, default = 0, n = 4) +
           lag(tmean_sm, default = 0, n = 5))/6,
         cgdd_12c_7d = (GDD_12Cbase + lag(GDD_12Cbase, default = 0) + 
           lag(GDD_12Cbase, default = 0, n = 2) + 
           lag(GDD_12Cbase, default = 0, n = 3) +
           lag(GDD_12Cbase, default = 0, n = 4) +
           lag(GDD_12Cbase, default = 0, n = 5) +
           lag(GDD_12Cbase, default = 0, n = 6))/7,
         tave_7d = (tmean_sm + lag(tmean_sm, default = 0) + 
           lag(tmean_sm, default = 0, n = 2) + 
           lag(tmean_sm, default = 0, n = 3) +
           lag(tmean_sm, default = 0, n = 4) +
           lag(tmean_sm, default = 0, n = 5) +
           lag(tmean_sm, default = 0, n = 6))/7,
         cgdd_12c_14d = (GDD_12Cbase + lag(GDD_12Cbase, default = 0) + 
           lag(GDD_12Cbase, default = 0, n = 2) + 
           lag(GDD_12Cbase, default = 0, n = 3) +
           lag(GDD_12Cbase, default = 0, n = 4) +
           lag(GDD_12Cbase, default = 0, n = 5) +
           lag(GDD_12Cbase, default = 0, n = 6) +
           lag(GDD_12Cbase, default = 0, n = 7) +
           lag(GDD_12Cbase, default = 0, n = 8) +
           lag(GDD_12Cbase, default = 0, n = 9) +
           lag(GDD_12Cbase, default = 0, n = 10) +
           lag(GDD_12Cbase, default = 0, n = 11) +
           lag(GDD_12Cbase, default = 0, n = 12) +
           lag(GDD_12Cbase, default = 0, n = 13))/14,
         tave_14d = (tmean_sm + lag(tmean_sm, default = 0) + 
           lag(tmean_sm, default = 0, n = 2) + 
           lag(tmean_sm, default = 0, n = 3) +
           lag(tmean_sm, default = 0, n = 4) +
           lag(tmean_sm, default = 0, n = 5) +
           lag(tmean_sm, default = 0, n = 6) +
           lag(tmean_sm, default = 0, n = 7) +
           lag(tmean_sm, default = 0, n = 8) +
           lag(tmean_sm, default = 0, n = 9) +
           lag(tmean_sm, default = 0, n = 10) +
           lag(tmean_sm, default = 0, n = 11) +
           lag(tmean_sm, default = 0, n = 12) +
           lag(tmean_sm, default = 0, n = 13))/14,
         cgdd_12c_21d = (GDD_12Cbase + lag(GDD_12Cbase, default = 0) + 
           lag(GDD_12Cbase, default = 0, n = 2) + 
           lag(GDD_12Cbase, default = 0, n = 3) +
           lag(GDD_12Cbase, default = 0, n = 4) +
           lag(GDD_12Cbase, default = 0, n = 5) +
           lag(GDD_12Cbase, default = 0, n = 6) +
           lag(GDD_12Cbase, default = 0, n = 7) +
           lag(GDD_12Cbase, default = 0, n = 8) +
           lag(GDD_12Cbase, default = 0, n = 9) +
           lag(GDD_12Cbase, default = 0, n = 10) +
           lag(GDD_12Cbase, default = 0, n = 11) +
           lag(GDD_12Cbase, default = 0, n = 12) +
           lag(GDD_12Cbase, default = 0, n = 13) +
           lag(GDD_12Cbase, default = 0, n = 14) +
           lag(GDD_12Cbase, default = 0, n = 15) +
           lag(GDD_12Cbase, default = 0, n = 16) +
           lag(GDD_12Cbase, default = 0, n = 17) +
           lag(GDD_12Cbase, default = 0, n = 18) +
           lag(GDD_12Cbase, default = 0, n = 19) +
           lag(GDD_12Cbase, default = 0, n = 20))/21,
         tave_21d = (tmean_sm + lag(tmean_sm, default = 0) + 
           lag(tmean_sm, default = 0, n = 2) + 
           lag(tmean_sm, default = 0, n = 3) +
           lag(tmean_sm, default = 0, n = 4) +
           lag(tmean_sm, default = 0, n = 5) +
           lag(tmean_sm, default = 0, n = 6) +
           lag(tmean_sm, default = 0, n = 7) +
           lag(tmean_sm, default = 0, n = 8) +
           lag(tmean_sm, default = 0, n = 9) +
           lag(tmean_sm, default = 0, n = 10) +
           lag(tmean_sm, default = 0, n = 11) +
           lag(tmean_sm, default = 0, n = 12) +
           lag(tmean_sm, default = 0, n = 13) +
           lag(tmean_sm, default = 0, n = 14) +
           lag(tmean_sm, default = 0, n = 15) +
           lag(tmean_sm, default = 0, n = 16) +
           lag(tmean_sm, default = 0, n = 17) +
           lag(tmean_sm, default = 0, n = 18) +
           lag(tmean_sm, default = 0, n = 19) +
           lag(tmean_sm, default = 0, n = 20))/21,
         cgdd_12c_28d = (GDD_12Cbase + lag(GDD_12Cbase, default = 0) + 
           lag(GDD_12Cbase, default = 0, n = 2) + 
           lag(GDD_12Cbase, default = 0, n = 3) +
           lag(GDD_12Cbase, default = 0, n = 4) +
           lag(GDD_12Cbase, default = 0, n = 5) +
           lag(GDD_12Cbase, default = 0, n = 6) +
           lag(GDD_12Cbase, default = 0, n = 7) +
           lag(GDD_12Cbase, default = 0, n = 8) +
           lag(GDD_12Cbase, default = 0, n = 9) +
           lag(GDD_12Cbase, default = 0, n = 10) +
           lag(GDD_12Cbase, default = 0, n = 11) +
           lag(GDD_12Cbase, default = 0, n = 12) +
           lag(GDD_12Cbase, default = 0, n = 13) +
           lag(GDD_12Cbase, default = 0, n = 14) +
           lag(GDD_12Cbase, default = 0, n = 15) +
           lag(GDD_12Cbase, default = 0, n = 16) +
           lag(GDD_12Cbase, default = 0, n = 17) +
           lag(GDD_12Cbase, default = 0, n = 18) +
           lag(GDD_12Cbase, default = 0, n = 19) +
           lag(GDD_12Cbase, default = 0, n = 20) +
           lag(GDD_12Cbase, default = 0, n = 21) +
           lag(GDD_12Cbase, default = 0, n = 22) +
           lag(GDD_12Cbase, default = 0, n = 23) +
           lag(GDD_12Cbase, default = 0, n = 24) +
           lag(GDD_12Cbase, default = 0, n = 25) +
           lag(GDD_12Cbase, default = 0, n = 26) +
           lag(GDD_12Cbase, default = 0, n = 27))/28,
         tave_28d = (tmean_sm + lag(tmean_sm, default = 0) + 
           lag(tmean_sm, default = 0, n = 2) + 
           lag(tmean_sm, default = 0, n = 3) +
           lag(tmean_sm, default = 0, n = 4) +
           lag(tmean_sm, default = 0, n = 5) +
           lag(tmean_sm, default = 0, n = 6) +
           lag(tmean_sm, default = 0, n = 7) +
           lag(tmean_sm, default = 0, n = 8) +
           lag(tmean_sm, default = 0, n = 9) +
           lag(tmean_sm, default = 0, n = 10) +
           lag(tmean_sm, default = 0, n = 11) +
           lag(tmean_sm, default = 0, n = 12) +
           lag(tmean_sm, default = 0, n = 13) +
           lag(tmean_sm, default = 0, n = 14) +
           lag(tmean_sm, default = 0, n = 15) +
           lag(tmean_sm, default = 0, n = 16) +
           lag(tmean_sm, default = 0, n = 17) +
           lag(tmean_sm, default = 0, n = 18) +
           lag(tmean_sm, default = 0, n = 19) +
           lag(tmean_sm, default = 0, n = 20) +
           lag(tmean_sm, default = 0, n = 21) +
           lag(tmean_sm, default = 0, n = 22) +
           lag(tmean_sm, default = 0, n = 23) +
           lag(tmean_sm, default = 0, n = 24) +
           lag(tmean_sm, default = 0, n = 25) +
           lag(tmean_sm, default = 0, n = 26) +
           lag(tmean_sm, default = 0, n = 27))/28,
         )

```

```{r}
#| eval: false
wea_ten_sites
```

# Define phenotypes

```{r}
#| eval: false
#| 
Tbase <- 12

phe_gr_fl <- phe_2019 %>%
  mutate(JDAY_EXP = case_when(YEAR == 2018 ~ JDAY,
                              YEAR == 2019 ~ JDAY + 365,
                              YEAR == 2020 ~ JDAY + (365*2),
                              YEAR == 2021 ~ JDAY + (365*3),
                              TRUE ~ NA_real_)) %>%
  select(-JDAY) %>%
  pivot_wider(names_from = PHE, values_from = JDAY_EXP) %>%
  left_join(select(sites, SITE, manu_site)) %>%
  mutate(Region = case_when(manu_site %in% c("SD", "MO", "IL", "MI", "NE") ~ "North",
                            manu_site %in% c("TX1", "TX2", "TX3", "TX4") ~ "Texas",
                                             TRUE ~ "OK"))

tmp2 <- wea_ten_sites %>%
  select(-Year)

gr_ten_sites <- phe_gr_fl %>%
  ungroup() %>%
  mutate(GR50 = floor(GR50)) %>%
  filter(!is.na(GR50)) %>%
  left_join(tmp2, by = c("manu_site", "GR50" = "JDAY_EXP")) %>%
  select(-SITE, -FL50, -(Working_date:wndk), -Tdrnl, -(Latitude:Elevation), -(tmax_sm:tmean_sm), -DLYN) %>%
  rename(crain_1d = prcp, dyln_gr50 = DYLN, cgdd_12c_1d = GDD_12Cbase, tave_1d = Tmean)

fl_ten_sites <- phe_gr_fl %>%
  ungroup() %>%
  filter(!is.na(FL50)) %>%
  mutate(FL50 = floor(FL50),
         GR50 = floor(GR50)) %>%
  left_join(tmp2, by = c("manu_site", "FL50" = "JDAY_EXP")) %>%
  select(-SITE, -(Working_date:wndk), -Tdrnl, -(Latitude:Elevation), -(tmax_sm:tmean_sm), -DLYN) %>%
  rename(crain_1d = prcp, dyln_gr50 = DYLN, cgdd_12c_1d = GDD_12Cbase, tave_1d = Tmean)
# 11 September flowering dates in 2021 at Pickle have NA's for weather values. Decided to let this be.

```

## save weather-based phenotypes

```{r}
#| eval: false
gr_ten_sites %>%
  saveRDS(file = here("data", "Weather_related_phe_GR50_2019.rds"))
fl_ten_sites %>%
  saveRDS(file = here("data", "Weather_related_phe_FL50_2019.rds"))
```

# --- can start here

# Covar csv for greedy mash algorithm

Make & save hypothesis matrices in a hypothesis_matrices directory in data. Then run the greedy mash algorithm again.

phe_hyp \<- c("cgdd_12c_10d", "cgdd_12c_18d", "cgdd_12c_5d", "tave_5d", "tave_10d", "tave_18d") phe_hyp \<- c("FL50", "GR50", "dyln_fl50", "dyln_change_sec", "cgdd_12c_gr2fl", "crain_gr2fl", "crain_1d", "crain_3d", "crain_5d")

### load weather phenotypes

```{r}
gr_ten_sites <- readRDS(file = here("data", 
                                    "Weather_related_phe_GR50_2019.rds"))
fl_ten_sites <- readRDS(file = here("data", 
                                    "Weather_related_phe_FL50_2019.rds"))
```

```{r}
phe_hyp <- colnames(fl_ten_sites)[c(5,9:51)]
colnames(gr_ten_sites)[8:50]
```

## Calculate heritability for diagonal

I don't have access to ASREML any more, so need a different package to do this.

### sketch out how h2 is calculated in rrBLUP

Use the kinship matrix I've already calculated (using the van Raden method, using switchgrassGWAS::pvdiv_kinship()) using the SNPs as the K matrix.

```{r}
#| eval: false


library(rrBLUP)
k_full <- read_rds("~/Github/pvdiv-genome/tensite_twoyear/Kinship_van_Raden_630_individuals_SNPs_r2_20percent.rds")
fl_ten_sites
colnames(k_full)

phe_one <- fl_ten_sites %>% filter(manu_site == "TX1") %>%
  filter(WHERE != "FWCR") %>%
  group_by(PLANT_ID) %>%
  summarise(crain_1d = mean(crain_1d, na.rm = TRUE)) %>%
  filter(!is.na(PLANT_ID))
k_in_phe <- which(colnames(k_full) %in% phe_one$PLANT_ID)
k_one <- k_full[k_in_phe, k_in_phe]

nrow(k_one)
nrow(phe_one)
mod2 <- mixed.solve(y = phe_one$crain_1d, K = k_one)
h2 <- mod2$Vu/(mod2$Vu + mod2$Ve)
```

Another error: "Error in mash(data, covmats) : All U_scaled matrices should be positive semi-definite

So I should adjust these to make sure all are positive semi-definite, too, in addition to replacing the diagonals with h2.

### Loop to calculate covar for flowering

```{r}
#| eval: false


metadata <- read_rds(here("data", "metadata.rds"))
subpop_v2 <- list(all = c("Gulf", "Midwest"), midwest = "Midwest",
                  gulf = "Gulf")
year_v = c(2019, 2020, 2021)

fl_ten_sites <- fl_ten_sites %>%
  left_join(select(metadata, PLANT_ID, SUBPOP)) %>%
  rename(Year = YEAR)
fl_ten_sites$PLANT_ID <- factor(fl_ten_sites$PLANT_ID, levels = colnames(k_full))

# change based on phenotype ---------------
#phe_hyp <- c("FL50", "GR50", "dyln_fl50", "dyln_change_sec", 
#             "dyln_change_sec_7d_prior", "dyln_change_sec_14d_prior", 
#             "dyln_7d_prior", "dyln_14d_prior", "cgdd_12c_gr2fl", 
#             "crain_gr2fl", "crain_1d", "crain_3d", "crain_5d")

phe_hyp <- colnames(fl_ten_sites)[c(5,9:51)]
i=2
k=1

U_hyp_2019 <- list()
for(i in seq_along(phe_hyp)){
  for(k in seq_along(subpop_v2)){

    cov_df <- fl_ten_sites %>%
      ungroup() %>%
      filter(SUBPOP %in% subpop_v2[[k]]) %>%
      filter(Year %in% 2019) %>%
      select(PLANT_ID, SUBPOP, manu_site, phe_hyp[i]) %>%
      group_by(PLANT_ID, SUBPOP, manu_site) %>%
      mutate(IND = row_number()) %>%
      pivot_wider(names_from = manu_site, values_from = phe_hyp[i]) %>%
      mutate(PLANT_ID = as.factor(PLANT_ID),
             IND = as.factor(IND)) %>%
      select(PLANT_ID, SUBPOP, IND, MI, MO, NE, OK, SD, TX1, TX2, TX3) %>% #####  IL,
      replace_na(list(MI = 0, MO = 0, NE = 0, OK = 0, SD = 0, TX1 = 0, TX2 = 0, 
                      TX3 = 0))
    
    cor_phe <- cor(cov_df[,-(1:3)], use = "pairwise")
    # Set diagonal of this matrix = heritability within each garden
    h2_diag <- c()
    site_names <- c("MI", "MO", "NE", "OK", "SD", "TX1", "TX2", "TX3")
    for(j in seq_along(site_names)) {
      phe_one <- fl_ten_sites %>% filter(manu_site == site_names[j]) %>%
        filter(WHERE != "FWCR") %>%
        group_by(PLANT_ID) %>%
        summarise(phenotype = mean(!! sym(phe_hyp[i]), na.rm = TRUE)) %>%
        filter(!is.na(PLANT_ID))
      k_in_phe <- which(colnames(k_full) %in% phe_one$PLANT_ID)
      k_one <- k_full[k_in_phe, k_in_phe]
      mod2 <- mixed.solve(y = phe_one$phenotype, K = k_one)
      h2_diag[j] <- mod2$Vu/(mod2$Vu + mod2$Ve)
    }
    
    diag(cor_phe) <- h2_diag
    if (!matrixcalc::is.positive.semi.definite(cor_phe)) {
      cor_phe <- Matrix::nearPD(cor_phe)
    }
    U_hyp_2019 <- list.prepend(U_hyp_2019, cor_phe)
    names(U_hyp_2019)[1] <- paste0("flowering.", names(subpop_v2)[k], ".", 
                                   phe_hyp[i], ".U.mat")
  }
}

U_hyp_2019

# Test that every matrix is positive semi definite. Should all be true now changed code above.
U_psd <- c() 
for (i in seq_along(U_hyp_2019)) {
  if (is.matrix(U_hyp_2019[[i]])) {
    U_psd[i] <- matrixcalc::is.positive.semi.definite(U_hyp_2019[[i]])
  } else {
    U_psd[i] <- matrixcalc::is.positive.semi.definite(as.matrix(U_hyp_2019[[i]]$mat))
  }
  
}


for (i in seq_along(U_hyp_2019)) {
  if (is.matrix(U_hyp_2019[[i]])) {
    matrixout = matrix(unlist(U_hyp_2019[[i]]), ncol = 8, byrow = TRUE)
  } else {
    matrixout = matrix(unlist(U_hyp_2019[[i]]$mat), ncol = 8, byrow = TRUE)
  }
  row.names(matrixout) = site_names
  colnames(matrixout) = site_names
  #print(matrixout)
  write.csv(matrixout, file = here("analysis", "mash_greedy_algorithm", 
                                   "mash_h2_diag_covar", "matrices", 
                                   paste0(names(U_hyp_2019)[i], ".csv")))
}




```

Another error: "Error in mash(data, covmats) : All U_scaled matrices should be positive semi-definite

### Loop to calculate covar for greenup

```{r}
#| eval: false
#| 
gr_ten_sites <- gr_ten_sites %>%
  left_join(select(metadata, PLANT_ID, SUBPOP)) %>%
  rename(Year = YEAR)

# change based on phenotype ---------------
#phe_hyp <- c("cgdd_12c_10d", "cgdd_12c_20d", "cgdd_12c_5d", 
#             "tave_5d", "tave_10d", "tave_20d")
phe_hyp <- colnames(gr_ten_sites)[8:50]
i=1
k=1

U_hyp_2019 <- list()
for(i in seq_along(phe_hyp)){
  for(k in seq_along(subpop_v2)){

    cov_df <- gr_ten_sites %>%
      ungroup() %>%
      filter(SUBPOP %in% subpop_v2[[k]]) %>%
      filter(Year %in% 2019) %>%
      select(PLANT_ID, SUBPOP, manu_site, phe_hyp[i]) %>%
      group_by(PLANT_ID, SUBPOP, manu_site) %>%
      mutate(IND = row_number()) %>%
      pivot_wider(names_from = manu_site, values_from = phe_hyp[i]) %>%
      mutate(PLANT_ID = as.factor(PLANT_ID),
             IND = as.factor(IND)) %>%
      select(PLANT_ID, SUBPOP, IND, MI, MO, NE, OK, SD, TX1, TX2, TX3) #####  IL,
    
    cor_phe <- cor(cov_df[,-(1:3)], use = "pairwise")
    # Set diagonal of this matrix = heritability within each garden
    h2_diag <- c()
    site_names <- c("MI", "MO", "NE", "OK", "SD", "TX1", "TX2", "TX3")
    for(j in seq_along(site_names)) {
      phe_one <- fl_ten_sites %>% filter(manu_site == site_names[j]) %>%
        filter(WHERE != "FWCR") %>%
        group_by(PLANT_ID) %>%
        summarise(phenotype = mean(!! sym(phe_hyp[i]), na.rm = TRUE)) %>%
        filter(!is.na(PLANT_ID))
      k_in_phe <- which(colnames(k_full) %in% phe_one$PLANT_ID)
      k_one <- k_full[k_in_phe, k_in_phe]
      mod2 <- mixed.solve(y = phe_one$phenotype, K = k_one)
      h2_diag[j] <- mod2$Vu/(mod2$Vu + mod2$Ve)
    }
    
    diag(cor_phe) <- h2_diag
    if (!matrixcalc::is.positive.semi.definite(cor_phe)) {
      cor_phe <- Matrix::nearPD(cor_phe)
    }

    U_hyp_2019 <- list.prepend(U_hyp_2019, cor_phe)
    names(U_hyp_2019)[1] <- paste0("greenup.", names(subpop_v2)[k], ".", phe_hyp[i], ".U.mat")
  }
}

for (i in seq_along(U_hyp_2019)) {
  if (is.matrix(U_hyp_2019[[i]])) {
    matrixout = matrix(unlist(U_hyp_2019[[i]]), ncol = 8, byrow = TRUE)
  } else {
    matrixout = matrix(unlist(U_hyp_2019[[i]]$mat), ncol = 8, byrow = TRUE)
  }
  row.names(matrixout) = site_names
  colnames(matrixout) = site_names
  #print(matrixout)
  write.csv(matrixout, file = here("analysis", "mash_greedy_algorithm", 
                                   "mash_h2_diag_covar", "matrices", 
                                   paste0(names(U_hyp_2019)[i], ".csv")))
}



```

### Midwest covar fewer sites

#### flowering: 6 sites

MI, MO, SD, TX1, TX2, TX3

```{r flowering midwest}
#| eval: false

phe_hyp <- colnames(fl_ten_sites)[c(5,9:51)]
i=2
k=2

U_hyp_2019 <- list()
for(i in seq_along(phe_hyp)){
  
    cov_df <- fl_ten_sites %>%
      ungroup() %>%
      filter(SUBPOP %in% subpop_v2[[k]]) %>%
      filter(Year %in% 2019) %>%
      select(PLANT_ID, SUBPOP, manu_site, phe_hyp[i]) %>%
      group_by(PLANT_ID, SUBPOP, manu_site) %>%
      mutate(IND = row_number()) %>%
      pivot_wider(names_from = manu_site, values_from = phe_hyp[i]) %>%
      mutate(PLANT_ID = as.factor(PLANT_ID),
             IND = as.factor(IND)) %>%
      select(PLANT_ID, SUBPOP, IND, MI, MO, SD, TX1, TX2, TX3) %>% #####  IL,
      replace_na(list(MI = 0, MO = 0, SD = 0, TX1 = 0, TX2 = 0, 
                      TX3 = 0))
    
    cor_phe <- cor(cov_df[,-(1:3)], use = "pairwise")
    # Set diagonal of this matrix = heritability within each garden
    h2_diag <- c()
    site_names <- c("MI", "MO", "SD", "TX1", "TX2", "TX3")
    for(j in seq_along(site_names)) {
      phe_one <- fl_ten_sites %>% filter(manu_site == site_names[j]) %>%
        filter(WHERE != "FWCR") %>%
        group_by(PLANT_ID) %>%
        summarise(phenotype = mean(!! sym(phe_hyp[i]), na.rm = TRUE)) %>%
        filter(!is.na(PLANT_ID))
      k_in_phe <- which(colnames(k_full) %in% phe_one$PLANT_ID)
      k_one <- k_full[k_in_phe, k_in_phe]
      mod2 <- mixed.solve(y = phe_one$phenotype, K = k_one)
      h2_diag[j] <- mod2$Vu/(mod2$Vu + mod2$Ve)
    }
    
    diag(cor_phe) <- h2_diag
    if (!matrixcalc::is.positive.semi.definite(cor_phe)) {
      cor_phe <- Matrix::nearPD(cor_phe)
    }
    U_hyp_2019 <- list.prepend(U_hyp_2019, cor_phe)
    names(U_hyp_2019)[1] <- paste0("flowering.", names(subpop_v2)[k], ".", 
                                   phe_hyp[i], ".U.mat")
}

U_hyp_2019

# Test that every matrix is positive semi definite. Should all be true now changed code above.
U_psd <- c() 
for (i in seq_along(U_hyp_2019)) {
  if (is.matrix(U_hyp_2019[[i]])) {
    U_psd[i] <- matrixcalc::is.positive.semi.definite(U_hyp_2019[[i]])
  } else {
    U_psd[i] <- matrixcalc::is.positive.semi.definite(as.matrix(U_hyp_2019[[i]]$mat))
  }
  
}


for (i in seq_along(U_hyp_2019)) {
  if (is.matrix(U_hyp_2019[[i]])) {
    matrixout = matrix(unlist(U_hyp_2019[[i]]), ncol = 6, byrow = TRUE)
  } else {
    matrixout = matrix(unlist(U_hyp_2019[[i]]$mat), ncol = 6, byrow = TRUE)
  }
  row.names(matrixout) = site_names
  colnames(matrixout) = site_names
  #print(matrixout)
  write.csv(matrixout, file = here("analysis", "mash_greedy_algorithm", 
                                   "mash_h2_diag_covar", "midwest_flowering", "matrices", 
                                   paste0(names(U_hyp_2019)[i], ".csv")))
}



```

```{r}
workingdir <- here("analysis", "mash_greedy_algorithm", 
                                   "mash_h2_diag_covar", "midwest_flowering")
pheno = "flowering"
betas = read.table(here(workingdir, "combined_mash_effects", paste0( pheno,'.midwest.betas.random.txt')))
stderrs = read.table(here(workingdir, "combined_mash_stderrs", paste0( pheno,'.midwest.stderrs.random.txt')))

mat_betas = matrix(unlist(betas),ncol=6,byrow = TRUE)
mat_stderrs = matrix(unlist(stderrs),ncol=6,byrow = TRUE)

sites = c('MI','MO','SD','TX1','TX2','TX3')
data=mash_set_data(mat_betas,mat_stderrs) 

canonical = cov_canonical(data = data)
matnames = ls(canonical)
for (matrix in matnames) {
  if (matrix %in% c('equal_effects','identity','simple_het_1','simple_het_2','simple_het_3')) {
  matrixout = matrix(unlist(canonical[matrix]), ncol = 6, byrow = TRUE)
  row.names(matrixout) = sites
  colnames(matrixout) = sites
  write.csv(matrixout, file = here(workingdir, "matrices", paste0(pheno,'.', matrix, '.csv')))
  }
}
print(canonical)
for (i in 1:6) {
  singleton = paste0('singletons_',i)
  print(singleton)
  singmat = canonical[singleton]
  site = sites[i]
  
  singmat = matrix(unlist(canonical[singleton]),ncol = 6, byrow = TRUE)
  row.names(singmat) = sites
  colnames(singmat) = sites
  write.csv(singmat, file = here(workingdir, "matrices", paste0(pheno, '.singleton.', site, '.csv')))
}

canonical = cov_pca(data,5)
cohort = "midwest"
effect = "random"
matnames = ls(canonical)
for (mat in matnames) {
  matrixout = matrix(unlist(canonical[mat]),ncol=6,byrow=TRUE)
  row.names(matrixout) = sites
  colnames(matrixout) = sites
  print(matrixout)
  write.csv(matrixout, file = here(workingdir, "matrices",
                                   paste0(pheno,'.', cohort,'.', effect,'.', mat, '.csv')))
}

```

#### greenup: 7 sites

MI, MO, NE, OK, TX1, TX2, TX3

```{r}
#| eval: false

phe_hyp <- colnames(gr_ten_sites)[8:50]
i=1
k=2

U_hyp_2019 <- list()
for(i in seq_along(phe_hyp)){

    cov_df <- gr_ten_sites %>%
      ungroup() %>%
      filter(SUBPOP %in% subpop_v2[[k]]) %>%
      filter(Year %in% 2019) %>%
      select(PLANT_ID, SUBPOP, manu_site, phe_hyp[i]) %>%
      group_by(PLANT_ID, SUBPOP, manu_site) %>%
      mutate(IND = row_number()) %>%
      pivot_wider(names_from = manu_site, values_from = phe_hyp[i]) %>%
      mutate(PLANT_ID = as.factor(PLANT_ID),
             IND = as.factor(IND)) %>%
      select(PLANT_ID, SUBPOP, IND, MI, MO, NE, OK, TX1, TX2, TX3) #####  IL,
    
    cor_phe <- cor(cov_df[,-(1:3)], use = "pairwise")
    # Set diagonal of this matrix = heritability within each garden
    h2_diag <- c()
    site_names <- c("MI", "MO", "NE", "OK", "TX1", "TX2", "TX3")
    for(j in seq_along(site_names)) {
      phe_one <- fl_ten_sites %>% filter(manu_site == site_names[j]) %>%
        filter(WHERE != "FWCR") %>%
        group_by(PLANT_ID) %>%
        summarise(phenotype = mean(!! sym(phe_hyp[i]), na.rm = TRUE)) %>%
        filter(!is.na(PLANT_ID))
      k_in_phe <- which(colnames(k_full) %in% phe_one$PLANT_ID)
      k_one <- k_full[k_in_phe, k_in_phe]
      mod2 <- mixed.solve(y = phe_one$phenotype, K = k_one)
      h2_diag[j] <- mod2$Vu/(mod2$Vu + mod2$Ve)
    }
    
    diag(cor_phe) <- h2_diag
    if (!matrixcalc::is.positive.semi.definite(cor_phe)) {
      cor_phe <- Matrix::nearPD(cor_phe)
    }

    U_hyp_2019 <- list.prepend(U_hyp_2019, cor_phe)
    names(U_hyp_2019)[1] <- paste0("greenup.", names(subpop_v2)[k], ".", phe_hyp[i], ".U.mat")
}

for (i in seq_along(U_hyp_2019)) {
  if (is.matrix(U_hyp_2019[[i]])) {
    matrixout = matrix(unlist(U_hyp_2019[[i]]), ncol = 7, byrow = TRUE)
  } else {
    matrixout = matrix(unlist(U_hyp_2019[[i]]$mat), ncol = 7, byrow = TRUE)
  }
  row.names(matrixout) = site_names
  colnames(matrixout) = site_names
  #print(matrixout)
  write.csv(matrixout, file = here("analysis", "mash_greedy_algorithm", 
                                   "mash_h2_diag_covar", "midwest_greenup",
                                   "matrices", 
                                   paste0(names(U_hyp_2019)[i], ".csv")))
}


```

```{r}
#| eval: false
workingdir <- here("analysis", "mash_greedy_algorithm", 
                                   "mash_h2_diag_covar", "midwest_greenup")
pheno = "greenup"
betas = read.table(here(workingdir, "combined_mash_effects", paste0( pheno,'.midwest.betas.random.txt')))
stderrs = read.table(here(workingdir, "combined_mash_stderrs", paste0( pheno,'.midwest.stderrs.random.txt')))

mat_betas = matrix(unlist(betas),ncol=7,byrow = TRUE)
mat_stderrs = matrix(unlist(stderrs),ncol=7,byrow = TRUE)

sites = c('MI','MO','NE', 'OK','TX1','TX2','TX3')
data=mash_set_data(mat_betas,mat_stderrs) 

canonical = cov_canonical(data = data)
matnames = ls(canonical)
for (matrix in matnames) {
  if (matrix %in% c('equal_effects','identity','simple_het_1','simple_het_2','simple_het_3')) {
  matrixout = matrix(unlist(canonical[matrix]), ncol = 7, byrow = TRUE)
  row.names(matrixout) = sites
  colnames(matrixout) = sites
  write.csv(matrixout, file = here(workingdir, "matrices", paste0(pheno,'.', matrix, '.csv')))
  }
}
print(canonical)
for (i in 1:7) {
  singleton = paste0('singletons_',i)
  print(singleton)
  singmat = canonical[singleton]
  site = sites[i]
  
  singmat = matrix(unlist(canonical[singleton]),ncol = 7, byrow = TRUE)
  row.names(singmat) = sites
  colnames(singmat) = sites
  write.csv(singmat, file = here(workingdir, "matrices", paste0(pheno, '.singleton.', site, '.csv')))
}

canonical = cov_pca(data,5)
cohort = "midwest"
effect = "random"
matnames = ls(canonical)
for (mat in matnames) {
  matrixout = matrix(unlist(canonical[mat]),ncol = 7,byrow=TRUE)
  row.names(matrixout) = sites
  colnames(matrixout) = sites
  print(matrixout)
  write.csv(matrixout, file = here(workingdir, "matrices",
                                   paste0(pheno,'.', cohort,'.', effect,'.', mat, '.csv')))
}

```

#### Visualize correlation matrices

```{r}
#| eval: false
i=7
switchgrassGWAS::mash_plot_pairwise_sharing(corrmatrix = U_hyp_2019[[i]],
                                            reorder = FALSE)
switchgrassGWAS::mash_plot_pairwise_sharing(corrmatrix = U_hyp_2019[[i+1]],
                                            reorder = FALSE)
switchgrassGWAS::mash_plot_pairwise_sharing(corrmatrix = U_hyp_2019[[i+2]],
                                            reorder = FALSE) 
names(U_hyp_2019)[[i+2]]
```

# ---------------

## Step 3: Greedy Mash

# Info to run greedy mash algo

data/mash_switchgrass_models/mash/all_matrices/matrices hosts all covar mat (?) analysis/mash_greedy_algorithm/mash_switchgrass_models/mash/all_matrices/matrices has more? covar mat? Can cp from these matrices dir to mash_h2_diag_covar/matrices the following regex, which run.mash.greedy.search.py looks for:

'.singleton.*' '.identity.*' '.simple_het\_*.*' '.equal_effects.*' '.*PCA\*'

Set up new analysis/mash_greedy_algorithm/mash_1_to_28d_covar/ or subdirectory to have all the subdir necessary to run `run.mash.greedy.search.py` python script. I think these may have to be pre-generated for the script to work, and I'll make sure they're empty to keep there from being I/O issues I haven't tested for.

Make sure all matrices are present in matrices/ subdir and named & output appropriately for recognition

Make sure random and strong Bhat and Shat in combined_mash_effects and combined_mash_stderrs are appropriate - perhaps ultimately replace these with my inputs in mash/Subpop/inputs; perhaps use what's here as tests first

When I change to my inputs for effects & stderrs, I will need to adjust midwest covar & effects appropriately to reflect only 6 (flowering) and 7 (greenup) rows & columns used; the other GWAS were dropped as too low power or due to substantial phenotype data loss, & including them would give misleading results.

### Next steps

Redo Midwest: Remake Midwest covar matrices, including hypothesis, singleton, identity, simple het, equal effects, and data-driven matrices. Make mash_greedy.R variants for changed input dir & for different Midwest column numbers. Run two new run.mash.greedy.search.py commands: python run.mash.greedy.search.py -p greenup -c midwest -e random python run.mash.greedy.search.py -p flowering -c midwest -e random

Try Gulf & All with my known inputs: python run.mash.greedy.search.py -p greenup -c gulf -e random python run.mash.greedy.search.py -p greenup -c all -e random python run.mash.greedy.search.py -p flowering -c gulf -e random python run.mash.greedy.search.py -p flowering -c all -e random

Write inputs to mash_h2_diag_covar/All_inputs, Gulf_inputs, and Midwest_inputs, from the original mash work. Especially important for Midwest which has some poor GWAS at dropped sites. The inputs Sam used have no column or rownames and look to be tab delimited.

aka combined_mash_effects/greenup.all.betas.random.txt and combined_mash_stderrs/flowering.gulf.betas.strong.txt

I only really need the random ones here, run mash again on the strong effects below.

```{r}
#| eval: false
popkey = list(all = "Gulf_and_Midwest", midwest = "Midwest", gulf = "Gulf")
phekey = list(greenup = "GR50", flowering = "FL50")
# i=2; j=1

for (i in seq_along(popkey)) {
  for (j in seq_along(phekey)) {
    
    if (i == 2 & j == 1) {
      betas <- readRDS(file = here("analysis", "mash", popkey[[i]], "inputs", 
                                 paste0("B_hat_random_df_24000topSNPs_",
                                        phekey[[j]], "_", popkey[[i]], ".rds")))
      stderr <- readRDS(file = here("analysis", "mash", popkey[[i]], "inputs", 
                                 paste0("S_hat_random_df_24000topSNPs_",
                                        phekey[[j]], "_", popkey[[i]], ".rds")))
    } else if (i == 2 & j == 2) {
      betas <- readRDS(file = here("analysis", "mash", popkey[[i]], "inputs", 
                                 paste0("B_hat_random_df_33000topSNPs_",
                                        phekey[[j]], "_", popkey[[i]], ".rds")))
      stderr <- readRDS(file = here("analysis", "mash", popkey[[i]], "inputs", 
                                 paste0("S_hat_random_df_33000topSNPs_",
                                        phekey[[j]], "_", popkey[[i]], ".rds")))
    } else {
      betas <- readRDS(file = here("analysis", "mash", popkey[[i]], "inputs", 
                                 paste0("B_hat_random_df_19000topSNPs_",
                                        phekey[[j]], "_", popkey[[i]], ".rds")))
      stderr <- readRDS(file = here("analysis", "mash", popkey[[i]], "inputs", 
                                 paste0("S_hat_random_df_19000topSNPs_",
                                        phekey[[j]], "_", popkey[[i]], ".rds")))
    }
    write.table(betas, file = here("analysis", "mash_greedy_algorithm", 
                                   "mash_h2_diag_covar", 
                                   paste0(names(popkey)[i], "_inputs"), 
                                   paste0(names(phekey)[j], ".", 
                                          names(popkey)[i], 
                                          ".betas.random.txt")),
                row.names = FALSE, col.names = FALSE)
    write.table(stderr, file = here("analysis", "mash_greedy_algorithm", 
                                    "mash_h2_diag_covar", 
                                    paste0(names(popkey)[i], "_inputs"), 
                                    paste0(names(phekey)[j], ".", 
                                           names(popkey)[i], 
                                           ".stderrs.random.txt")),
                row.names = FALSE, col.names = FALSE)
  }
}

```

```{r}
#| eval: false
for (i in 1:35) {
  if (!dir.exists(here("analysis", "mash_greedy_algorithm", "mash_h2_diag_covar", "midwest_inputs", "likelihoods", paste0("step", i)))) {
    dir.create(here("analysis", "mash_greedy_algorithm", "mash_h2_diag_covar", "midwest_inputs", "likelihoods", paste0("step", i)))
  }
}
```

Run the pod.greedy.sh scripts from their dir, or run the python commands in those scripts.

Look at the results in the likelihood_paths files for the following data:

Using a set of covariance matrices with h2 on the diagonal, made positive semi-definite, and for multiple weather variable averages, 1-7d, 14,21,and28d averages before the greenup or flowering event.

Using the effects and standard errors that I used for my previous mash analysis. However I originally selected them, plus the reduced number of sites for the Midwest plants.

Only keep covariance matrices if they significantly improve the mash model likelihoods when added. This way, we know they improve the mash model and that they are distinct enough from others matrices that we added.

Using the random set of SNPs. Then, look at the mash results generated using these covariance matrices using a strong set of SNPs.

Given that the greedy algorithm, run on Sam's random inputs, however he generated or found those, gives many more covar matrices especially from Uhyp, I wonder if some repetition of this analysis would be valuable, before blowing these results all out of proportion in a paper. Either different random sets of effects, or effects from different years of data. Think on this. I definitely want to use my known inputs, not Sam's, as mine have a traceable history (or anyways more traceable).

# -----------------------------

# Step 4: Run mash

```{r}
#| eval: false
#| 
#| 

library(tidyverse)
library(bigsnpr)
library(switchgrassGWAS)
library(mashr)
library(rlist)
library(here)

source("~/Github/Functions_ggplot-theme-adjustments_2018-01-03.R")
mashdir <- here("analysis", "mash_greedy_algorithm", "mash_h2_diag_covar")

numSNPs_v <- c(19000, 19000, 19000, 19000, 24000, 33000)
suffix_v <- c("FL50_Gulf_and_Midwest", "FL50_Gulf", "GR50_Gulf_and_Midwest",
              "GR50_Gulf", "GR50_Midwest", "FL50_Midwest")
suffix_vli <- c("Gulf_and_Midwest", "Gulf", "Gulf_and_Midwest",
              "Gulf", "Midwest", "Midwest")
subpop_v <- list(Gulf_and_Midwest = "363g_12.1M", Midwest = "134g_8.8M", 
                 Gulf = "229g_10.3M")

pop_sc <- c("all", "gulf", "all", "gulf", "midwest", "midwest")
phe_sc <- c("flowering", "flowering", "greenup", "greenup", "greenup",
            "flowering")

Upaths <- c(here("analysis", "mash_greedy_algorithm", "mash_h2_diag_covar",
                 "all_inputs"),
            here("analysis", "mash_greedy_algorithm", "mash_h2_diag_covar",
                 "gulf_inputs"),
            here("analysis", "mash_greedy_algorithm", "mash_h2_diag_covar",
                 "all_inputs"),
            here("analysis", "mash_greedy_algorithm", "mash_h2_diag_covar",
                 "gulf_inputs"),
            here("analysis", "mash_greedy_algorithm", "mash_h2_diag_covar",
                 "midwest_greenup"),
            here("analysis", "mash_greedy_algorithm", "mash_h2_diag_covar",
                 "midwest_flowering"))

#   i = 4
for (i in 1:6) {  # change this for different scripts
  # B_hat_strong_df_19000topSNPs_FL50_Gulf_and_Midwest.rds
  # B_hat_strong_df_19000topSNPs_FL50_Gulf.rds
  # B_hat_strong_df_19000topSNPs_GR50_Gulf_and_Midwest.rds
  # B_hat_strong_df_19000topSNPs_GR50_Gulf.rds
  # B_hat_strong_df_24000topSNPs_GR50_Midwest.rds
  # B_hat_strong_df_33000topSNPs_FL50_Midwest.rds
  ## mash Gulf greenup
  numSNPs <- numSNPs_v[i]
  suffix <- suffix_v[i]
  Upath <- here(Upaths[i], "matrices")
  stopcondpath <- here(Upaths[i], "likelihood_paths")
  # use this one for the likelihood paths
  # Read in likelihood paths, then use that to read in matrices, then use those to run mash.

  U_greedy <- 
    read_csv(file = file.path(stopcondpath, 
                              paste0(phe_sc[i], ".", pop_sc[i], 
                                     ".random.stop.condition.csv"))) %>%
    filter(matrix != "0.0")
  ## Read in Uhyp
  
  U_list <- list()
  for (k in 1:nrow(U_greedy)) {
    U_single <- read_csv(file = file.path(Upath, U_greedy$matrix[k]), show_col_types = FALSE)
    # if conditions for Midwest
    if (i == 5) {
    # MI, MO, NE, OK, TX1, TX2, TX3 used for GR50  
      U_single <- U_single %>%
        filter(`...1` %in% c("MI", "MO", "NE", "OK", "TX1", "TX2", "TX3")) %>%
        select(`...1`, .data$MI, .data$MO, .data$NE, .data$OK, .data$TX1,
               .data$TX2, .data$TX3)
    } else if (i == 6) {
    # MI, MO, SD, TX1, TX2, TX3 used for FL50  
      U_single <- U_single %>%
        filter(`...1` %in% c("MI", "MO", "SD", "TX1", "TX2", "TX3")) %>%
        select(`...1`, .data$MI, .data$MO, .data$SD, .data$TX1, .data$TX2,
               .data$TX3)
    }
    U_single <- U_single %>%
      select(-`...1`)
    U_single <- as.matrix(unname(U_single)) 
    
    
    # format cov matrices correctly for mash
    U_list <- list.append(U_list, U_single)
  }
  names(U_list) <- str_remove(U_greedy$matrix, ".csv")
  
  lipath <- here("analysis", "mash", suffix_vli[i], "inputs")
  
  list_input <- switchgrassGWAS:::load_mash_df(path = lipath, 
                                               numSNPs = numSNPs,
                                               suffix = suffix)
  # Just run mash itself as the greedy choice of cov matrices changes mash run
  # enough that mash_standard_run will not perform correctly (eg it always adds
  # all canonical covariance matrices).
  Bhat_strong <- as.matrix(list_input$B_hat_strong)
  Shat_strong <- as.matrix(list_input$S_hat_strong)
  Bhat_random <- as.matrix(list_input$B_hat_random)
  Shat_random <- as.matrix(list_input$S_hat_random)
  
  data_r <- mashr::mash_set_data(Bhat_random, Shat_random)
  Vhat <- mashr::estimate_null_correlation_simple(data = data_r)
  
  data_strong <- mashr::mash_set_data(Bhat_strong, Shat_strong, V = Vhat)
  data_random <- mashr::mash_set_data(Bhat_random, Shat_random, V = Vhat)
  
  # Run mash on the random dataset using the random data w/ correlation structure
  message(paste0("Fit mash to the random tests using both data-driven and ",
                 "canonical covariances."))
  # U_c <- mashr::cov_canonical(data_random)
  m = mashr::mash(data_random, Ulist = U_list, outputlevel = 1)
  
  # Run mash on the strong dataset (or all data) using
  # the previous results from the random data
  message(paste0("Compute posterior matrices for the strong effects",
                 " using the mash fit from the
                   random tests."))
  m2 = mashr::mash(data_strong, g = get_fitted_g(m), fixg = TRUE)
  
  saveRDS(m2, file = file.path(mashdir,  
                                   paste0("Strong_mash_posterior_",
                                          "est_w_ahm_random_greedy_h2_diag_Ulist", 
                                          numSNPs, "_SNPs_",
                                          suffix, ".rds")))
  
  print(paste0(suffix, " mash outputs: "))
  print("Log likelihood with specified covariance matrices: ")
  print(get_loglik(m2), digits = 10)
  print("How many significant markers?")
  print(length(get_significant_results(m2)))
  switchgrassGWAS::mash_plot_covar(m2)
  switchgrassGWAS::mash_plot_manhattan_by_condition(m2)
  switchgrassGWAS::mash_plot_pairwise_sharing(m2)
  gxe <- switchgrassGWAS::get_GxE(m2)
  saveRDS(gxe, file = file.path(mashdir,  
                                   paste0("GxE_default_",
                                          "est_w_ahm_random_greedy_h2_diag_Ulist",
                                          numSNPs, "_SNPs_",
                                          suffix, "_greedy_Ulist.rds")))
}
```

# ----------------

Reasoning from Analysis_v0.6 script for dropping sites from the Midwest:

Some univariate GWAS for the Midwest had population structure issues. Mostly for greenup - even GR50 at MO was quite bad. Drop MO for GR50. Midwest_GR50_SD have values of zero for Bhat and Shat. Drop this from Midwest analyses.

# Step 5: Redo writeup & figures

## Load mash objects

```{r}
mashdir <- here("analysis", "mash_greedy_algorithm", "mash_h2_diag_covar")

numSNPs_v <- c(19000, 19000, 19000, 19000, 24000, 33000)
suffix_v <- c("FL50_Gulf_and_Midwest", "FL50_Gulf", "GR50_Gulf_and_Midwest",
              "GR50_Gulf", "GR50_Midwest", "FL50_Midwest")
```

```{r}
m_gulf_gr_hyp <- readRDS(file.path(mashdir,  
                                   paste0("Strong_mash_posterior_",
                                          "est_w_ahm_random_greedy_h2_diag_Ulist", 
                                          numSNPs_v[4], "_SNPs_",
                                          suffix_v[4], ".rds")))
m_gulf_fl_hyp <- readRDS(file.path(mashdir,  
                                   paste0("Strong_mash_posterior_",
                                          "est_w_ahm_random_greedy_h2_diag_Ulist", 
                                          numSNPs_v[2], "_SNPs_",
                                          suffix_v[2], ".rds")))

m_midw_gr_hyp <- readRDS(file.path(mashdir,  
                                   paste0("Strong_mash_posterior_",
                                          "est_w_ahm_random_greedy_h2_diag_Ulist", 
                                          numSNPs_v[5], "_SNPs_",
                                          suffix_v[5], ".rds")))
m_midw_fl_hyp <- readRDS(file.path(mashdir,  
                                   paste0("Strong_mash_posterior_",
                                          "est_w_ahm_random_greedy_h2_diag_Ulist", 
                                          numSNPs_v[6], "_SNPs_",
                                          suffix_v[6], ".rds")))

m_gam_gr_hyp <- readRDS(file.path(mashdir,  
                                   paste0("Strong_mash_posterior_",
                                          "est_w_ahm_random_greedy_h2_diag_Ulist", 
                                          numSNPs_v[3], "_SNPs_",
                                          suffix_v[3], ".rds")))
m_gam_fl_hyp <- readRDS(file.path(mashdir,  
                                   paste0("Strong_mash_posterior_",
                                          "est_w_ahm_random_greedy_h2_diag_Ulist", 
                                          numSNPs_v[1], "_SNPs_",
                                          suffix_v[1], ".rds")))

```

## Figure 2

```{r}
get_cov_type <- function(m, summarise = FALSE, subpop = FALSE){
  cov_df <- mash_plot_covar(m)
  cov_type <- cov_df$covar_df %>% 
    mutate(Type = case_when(grepl("PCA", `Covariance Matrix`) ~ "data-driven",
                            grepl("singleton", `Covariance Matrix`) ~
                              "canonical",
                            grepl("simple_het", `Covariance Matrix`) ~
                              "canonical",
                            grepl("no_effects", `Covariance Matrix`) ~
                              "canonical",
                            grepl("identity", `Covariance Matrix`) ~
                              "canonical",
                            grepl("equal_effects", `Covariance Matrix`) ~
                              "canonical",
                            grepl("U.mat$", `Covariance Matrix`) ~
                              "hypothesized",
                            TRUE ~ "other"
                            )) 
  if (summarise == TRUE) {
    cov_type <- cov_type %>%
      group_by(Type) %>%
      summarise(Mass = sum(Mass))
  }
  return(cov_type)
}

get_cov_type(m_gulf_gr_hyp, summarise = TRUE, subpop = TRUE)
get_cov_type(m_gulf_fl_hyp, summarise = TRUE, subpop = TRUE)
get_cov_type(m_midw_gr_hyp, summarise = FALSE, subpop = TRUE)
get_cov_type(m_midw_fl_hyp, summarise = TRUE, subpop = TRUE)
get_cov_type(m_gam_gr_hyp, summarise = FALSE, subpop = TRUE)
get_cov_type(m_gam_fl_hyp, summarise = TRUE, subpop = TRUE)
```

New theme for ggplot2 v 3.5

```{r}
theme_oeco <- theme_classic() +
  theme(axis.title = element_text(size = 10), 
        axis.text = element_text(size = 10), 
        axis.line.x = element_line(linewidth = 0.35, colour = 'grey50'),
        axis.line.y = element_line(linewidth = 0.35, colour = 'grey50'),
        axis.ticks = element_line(linewidth = 0.25, colour = 'grey50'), 
        legend.justification = c(1, 0.75), 
        legend.position = c(1, 0.9), 
        legend.key.size = unit(0.35, 'cm'),
        legend.title = element_blank(), 
        legend.text = element_text(size = 9),
        legend.background = element_blank(),
        plot.subtitle = element_text(size = 10, vjust = 0), #plot.margin = unit(c(0.35, 0, 0.25, 0), 'cm'),
        strip.background = element_blank(), 
        strip.text = element_text(hjust = 0.5, size = 10 ,vjust = 0), 
        strip.placement = 'outside', panel.spacing.x = unit(-0.5, 'cm'))
theme_set(theme_oeco)
```

```{r}
cov_gg <- mash_plot_covar(m_gulf_gr_hyp)
cov_gf <- mash_plot_covar(m_gulf_fl_hyp)

cov_mg <- mash_plot_covar(m_midw_gr_hyp)
cov_mf <- mash_plot_covar(m_midw_fl_hyp)

cov_gamg <- mash_plot_covar(m_gam_gr_hyp)
cov_gamf <- mash_plot_covar(m_gam_fl_hyp)

cov_gg$ggobject + 
  theme_oeco +
  ggtitle("Gulf greenup", subtitle = "64.5% SNP mass")
cov_gf$ggobject + 
  theme_oeco +
  ggtitle("Gulf flowering", subtitle = "33.0% SNP mass")
cov_mg$ggobject + 
  theme_oeco +
  ggtitle("Midwest greenup", subtitle = "0% SNP mass")
cov_mf$ggobject + 
  theme_oeco +
  ggtitle("Midwest flowering", subtitle = "22.6% SNP mass")
cov_gamg$ggobject + 
  theme_oeco +
  ggtitle("Gulf and Midwest greenup", subtitle = "32.7% SNP mass")
cov_gamf$ggobject + 
  theme_oeco +
  ggtitle("Gulf and Midwest flowering", subtitle = "0% SNP mass")
```

### covar

```{r get covar matrices picked by greedy mash}
get_greedy_Ulist <- function(i) {
  pop_sc <- c("all", "gulf", "all", "gulf", "midwest", "midwest")
  phe_sc <- c("flowering", "flowering", "greenup", "greenup", "greenup",
              "flowering")
  Upaths <- c(here("analysis", "mash_greedy_algorithm", "mash_h2_diag_covar",
                   "all_inputs"),
              here("analysis", "mash_greedy_algorithm", "mash_h2_diag_covar",
                   "gulf_inputs"),
              here("analysis", "mash_greedy_algorithm", "mash_h2_diag_covar",
                   "all_inputs"),
              here("analysis", "mash_greedy_algorithm", "mash_h2_diag_covar",
                   "gulf_inputs"),
              here("analysis", "mash_greedy_algorithm", "mash_h2_diag_covar",
                   "midwest_greenup"),
              here("analysis", "mash_greedy_algorithm", "mash_h2_diag_covar",
                   "midwest_flowering"))

#   i = 4
#for (i in 1:6) {  # change this for different scripts
  # B_hat_strong_df_19000topSNPs_FL50_Gulf_and_Midwest.rds
  # B_hat_strong_df_19000topSNPs_FL50_Gulf.rds
  # B_hat_strong_df_19000topSNPs_GR50_Gulf_and_Midwest.rds
  # B_hat_strong_df_19000topSNPs_GR50_Gulf.rds
  # B_hat_strong_df_24000topSNPs_GR50_Midwest.rds
  # B_hat_strong_df_33000topSNPs_FL50_Midwest.rds
  ## mash Gulf greenup
  Upath <- here(Upaths[i], "matrices")
  stopcondpath <- here(Upaths[i], "likelihood_paths")
  # use this one for the likelihood paths
  # Read in likelihood paths, then use that to read in matrices, then use those to run mash.

  U_greedy <- 
    read_csv(file = file.path(stopcondpath, 
                              paste0(phe_sc[i], ".", pop_sc[i], 
                                     ".random.stop.condition.csv"))) %>%
    filter(matrix != "0.0")
  ## Read in Uhyp
  
  U_list <- list()
  for (k in 1:nrow(U_greedy)) {
    U_single <- read_csv(file = file.path(Upath, U_greedy$matrix[k]), show_col_types = FALSE)
    # if conditions for Midwest
    if (i == 5) {
    # MI, MO, NE, OK, TX1, TX2, TX3 used for GR50  
      U_single <- U_single %>%
        filter(`...1` %in% c("MI", "MO", "NE", "OK", "TX1", "TX2", "TX3")) %>%
        select(`...1`, .data$MI, .data$MO, .data$NE, .data$OK, .data$TX1,
               .data$TX2, .data$TX3)
    } else if (i == 6) {
    # MI, MO, SD, TX1, TX2, TX3 used for FL50  
      U_single <- U_single %>%
        filter(`...1` %in% c("MI", "MO", "SD", "TX1", "TX2", "TX3")) %>%
        select(`...1`, .data$MI, .data$MO, .data$SD, .data$TX1, .data$TX2,
               .data$TX3)
    }
    
    # format cov matrices correctly for mash
    U_list <- list.append(U_list, U_single)
  }
  names(U_list) <- str_remove(U_greedy$matrix, ".csv") %>%
    enframe(value = "Covariance Matrix") %>%
  mutate(`Covariance Matrix` = str_replace(`Covariance Matrix`, "greenup.", ""),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "gulf.", ""),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "all.", ""),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "midwest.", ""),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "singleton.", "Single Effect "),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "simple_het_", "Simple Het. "),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "no_effects", "No Effects"),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "tave_1d.U.mat", "Temp Ave, 1d"),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "dyln_14d_prior.U.mat", "Daylength (14d prior)"),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "dyln_change_sec.U.mat", "Daylength change (s)"),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "flowering.", ""),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "crain_7d.U.mat", "Cumulative rainfall, 7d"),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "dyln_change_sec_2d_prior.U.mat", "Daylength change (s), 2d prior")
         ) %>% 
    select(`Covariance Matrix`) %>%
    as_vector()
  return(U_list)
}

#}
```

```{r pick covar matrices to plot fig 2}
plot_covar_Ulist_fig2 <- function(df, mf = FALSE, mg = FALSE, legend = FALSE) {
  if (mg) {
    df <- df %>%
      select(`...1`, TX1, TX2, TX3, OK, MO, NE, MI) 
  } else if (mf) {
    df <- df %>%
      select(`...1`, TX1, TX2, TX3, MO, MI, SD) 
  } else {
    df <- df %>%
      select(`...1`, TX1, TX2, TX3, OK, MO, NE, MI, SD) 
  }
  

df$`...1` <- factor(df$`...1`, levels = rev(c("TX1", "TX2", "TX3", "OK", "MO", "NE", "MI", "SD")))

  U1 <- df %>%
          pivot_longer(cols = -.data$`...1`, names_to = "colU",
                       values_to = "covar") %>%
          filter(!is.na(.data$covar)) %>%
    rename(rowU = `...1`)
  U1$colU <- factor(U1$colU, levels = colnames(df)[2:ncol(df)])
  U1$rowU <- factor(U1$rowU, levels = colnames(df)[2:ncol(df)])
  
  U1$Site_pair <- NA
for (i in 1:nrow(U1)) {
  v <- sort(c(U1$rowU[i], U1$colU[i]))
  U1$Site_pair[i] <- paste0(v[1], "_", v[2])
}
  
  plot_covar <- U1 %>%
    arrange(desc(rowU), desc(colU)) %>%
    distinct(Site_pair, .keep_all = TRUE) %>%
    ggplot(aes(x = .data$rowU, y = .data$colU)) +
    switchgrassGWAS::theme_oeco +
    geom_tile(aes(fill = .data$covar), na.rm = TRUE) +
    scale_fill_gradientn(colors = c("#30123BFF", "#4777EFFF", "#1BD0D5FF",
                                  "white", "#FE9B2DFF", "#DB3A07FF",
                                  "#7A0403FF"),
                         limits = c(-1, 1)) +
    theme_oeco 
  if (legend == FALSE) {
    plot_covar <- plot_covar +
    theme(legend.position = "none",
          axis.text = element_blank(),
          axis.ticks = element_blank(),
          axis.line.x = element_blank(),
          axis.line.y = element_blank(),
          axis.title.y.right = element_text()) +
    labs(x = "", y = "")
  } else if (legend == TRUE) {
      plot_covar <- plot_covar +
    theme(legend.position = "right",
          axis.text = element_blank(),
          axis.ticks = element_blank(),
          axis.line.x = element_blank(),
          axis.line.y = element_blank(),
          axis.title.y.right = element_text()) +
    labs(x = "", y = "")
    }
  
  return(plot_covar)
}
library(scales)
show_col(viridis_pal(option = "H")(8))
```

```{r}
Ulist_gamf <- get_greedy_Ulist(1)
Ulist_gf <- get_greedy_Ulist(2)
Ulist_gamg <- get_greedy_Ulist(3)
Ulist_gg <- get_greedy_Ulist(4)
Ulist_mg <- get_greedy_Ulist(5)
Ulist_mf <- get_greedy_Ulist(6)
Ulist_gf$`Cumulative rainfall, 7d`
Ulist_mg$dyln_change_sec_7d_prior.U.mat
```

```{r build panels of covar matrices for 2a}
pa01 <- plot_covar_Ulist_fig2(Ulist_gg$`Daylength (14d prior)`) + 
  labs(subtitle = "Daylength (14d prior)")
pa03 <- plot_covar_Ulist_fig2(Ulist_gg$cgdd_12c_6d.U.mat) + 
  labs(subtitle = "Cumulative GDD, 6d")

pa06 <- plot_covar_Ulist_fig2(Ulist_gf$`Cumulative rainfall, 7d`) + 
  labs(subtitle = "Cumulative rainfall, 7d")

pa04 <- plot_covar_Ulist_fig2(Ulist_mg$dyln_change_sec_7d_prior.U.mat, mg = TRUE) + 
  labs(subtitle = "Daylength change (s), 7d prior")
pa07 <- plot_covar_Ulist_fig2(Ulist_mf$`Daylength change (s), 2d prior`, mf = TRUE) + 
  labs(subtitle = "Daylength change (s), 2d prior")

pa02 <- plot_covar_Ulist_fig2(Ulist_gamg$`Daylength change (s)`) + 
  labs(subtitle = "Daylength change (s)")
pa05 <- plot_covar_Ulist_fig2(Ulist_gamg$`Temp Ave, 1d`) + 
  labs(subtitle = "Temp Ave, 1d")
pa08 <- plot_covar_Ulist_fig2(Ulist_gamf$crain_1d.U.mat) + 
  labs(subtitle = "Cumulative rainfall, 1d")

pa13 <- plot_covar_Ulist_fig2(Ulist_gf[[1]]) + 
  labs(subtitle = "identity (Mass <1%)") 
pa09 <- plot_covar_Ulist_fig2(Ulist_gf[[5]]) + 
  labs(subtitle = names(Ulist_gf)[5]) 
pa10 <- plot_covar_Ulist_fig2(Ulist_gf[[2]]) + 
  labs(subtitle = names(Ulist_gf)[2])
pa12 <- plot_covar_Ulist_fig2(Ulist_gg[[2]]) + 
  labs(subtitle = names(Ulist_gg)[2])
pa11 <- plot_covar_Ulist_fig2(Ulist_gf[[8]]) + 
  labs(subtitle = names(Ulist_gf)[8])
```

```{r build panels of barplots for fig 2}
cov_gr1 <- mash_plot_Ulist(m_gulf_gr_hyp, range = 2, limits = TRUE)
legend <- get_legend(cov_gr1) 
fig_eqeff <- plot_covar_Ulist_fig2(Ulist_mg[[2]], mg = TRUE) +
  labs(subtitle = "simple heterozygousity")

df_2a <- get_cov_type(m_gulf_gr_hyp, summarise = TRUE) %>%
  mutate(subpop = "Gulf",
         phenotype = "greenup")
df_2b <- get_cov_type(m_midw_gr_hyp, summarise = TRUE) %>%
  mutate(subpop = "Midwest",
         phenotype = "greenup")
df_2c <- get_cov_type(m_gam_gr_hyp, summarise = TRUE) %>%
  mutate(subpop = "Both",
         phenotype = "greenup")
df_2d <- get_cov_type(m_gulf_fl_hyp, summarise = TRUE) %>%
  mutate(subpop = "Gulf",
         phenotype = "flowering")
df_2e <- get_cov_type(m_midw_fl_hyp, summarise = TRUE) %>%
  mutate(subpop = "Midwest",
         phenotype = "flowering")
df_2f <- get_cov_type(m_gam_fl_hyp, summarise = TRUE) %>%
  mutate(subpop = "Both",
         phenotype = "flowering")
df_2gr_b <- df_2a %>% full_join(df_2b) %>% full_join(df_2c)
df_2fl_b <- df_2d %>% full_join(df_2e) %>% full_join(df_2f)

df_2a <- get_cov_type(m_gulf_gr_hyp) %>%
  mutate(subpop = "Gulf",
         phenotype = "greenup")
df_2b <- get_cov_type(m_midw_gr_hyp) %>%
  mutate(subpop = "Midwest",
         phenotype = "greenup")
df_2c <- get_cov_type(m_gam_gr_hyp) %>%
  mutate(subpop = "Both",
         phenotype = "greenup")
df_2d <- get_cov_type(m_gulf_fl_hyp) %>%
  mutate(subpop = "Gulf",
         phenotype = "flowering")
df_2e <- get_cov_type(m_midw_fl_hyp) %>%
  mutate(subpop = "Midwest",
         phenotype = "flowering")
df_2f <- get_cov_type(m_gam_fl_hyp) %>%
  mutate(subpop = "Both",
         phenotype = "flowering")
df_2gr_a <- df_2a %>% full_join(df_2b) %>% full_join(df_2c) %>%
  mutate(`Covariance Matrix` = str_replace(`Covariance Matrix`, "greenup.", ""),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "gulf.", ""),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "all.", ""),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "midwest.", ""),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "singleton.", "Single Effect "),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "simple_het_", "Simple Het. "),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "no_effects", "No Effects"),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "tave_1d.U.mat", " Temp Ave, 1d"),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "dyln_14d_prior.U.mat", " Daylength (14d prior)"),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "dyln_change_sec.U.mat", " Daylength change (s)")
         )
df_2fl_a <- df_2d %>% full_join(df_2e) %>% full_join(df_2f) %>%
  mutate(`Covariance Matrix` = str_replace(`Covariance Matrix`, "flowering.", ""),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "gulf.", ""),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "all.", ""),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "midwest.", ""),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "singleton.", "Single Effect "),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "simple_het_", "Simple Het. "),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "no_effects", "No Effects"),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "crain_7d.U.mat", "  Cumulative rainfall, 7d"),
         `Covariance Matrix` = str_replace(`Covariance Matrix`, "dyln_change_sec_2d_prior.U.mat", " Daylength change (s), 2d prior")
         )

df_2gr_b$subpop <- factor(df_2gr_b$subpop, levels = c("Gulf", "Midwest", "Both"))
df_2fl_b$subpop <- factor(df_2fl_b$subpop, levels = c("Gulf", "Midwest", "Both"))
df_2gr_a$subpop <- factor(df_2gr_a$subpop, levels = c("Gulf", "Midwest", "Both"))
df_2fl_a$subpop <- factor(df_2fl_a$subpop, levels = c("Gulf", "Midwest", "Both"))
df_2fl_a$Type <- factor(df_2fl_a$Type, levels = c("canonical", "hypothesized"))
df_2fl_a$Type <- factor(df_2fl_a$Type, levels = c("canonical", "hypothesized"))

f2b <- df_2gr_b %>%
  filter(Mass > 1e-05) %>%
  ggplot(aes(x = subpop, y = Mass)) + 
  geom_bar(aes(fill = Type), stat = "identity") +
  scale_fill_viridis_d(end = 0.9, option = "H") +
  theme_oeco + 
  theme(axis.title.x=element_blank(),
        legend.position = "none",
        axis.text.x=element_text(hjust = 1, vjust = 1, angle = 45))
f2d <- df_2fl_b %>%
  filter(Mass > 1e-05) %>%
  ggplot(aes(x = subpop, y = Mass)) + 
  geom_bar(aes(fill = Type), stat = "identity") +
  scale_fill_viridis_d(end = 0.9, option = "H") +
  theme_oeco + 
  theme(axis.title.x=element_blank(),
        legend.position = "none",
        axis.text.x=element_text(hjust = 1, vjust = 1, angle = 45))
f2a <- df_2gr_a %>%
  filter(Mass > 1e-06) %>%
  ggplot(aes(x = `Covariance Matrix`, y = Mass)) + 
  geom_bar(aes(fill = Type), stat = "identity") +
  facet_wrap(~subpop) +
  coord_flip() + scale_fill_viridis_d(end = 0.9, option = "H") +
  theme(legend.position = c(-0.4, 0.3),
        axis.text.x=element_text(hjust = 1, vjust = 1, angle = 45), 
        panel.spacing.x = unit(-0, 'cm')) #+ labs(x = "")
f2c <- df_2fl_a %>%
  filter(Mass > 1e-06) %>%
  ggplot(aes(x = `Covariance Matrix`, y = Mass)) + 
  geom_bar(aes(fill = Type), stat = "identity") +
  facet_wrap(~subpop) +
  coord_flip() + scale_fill_viridis_d(end = 0.9, option = "H") +
  theme(legend.position = "none",
        axis.text.x=element_text(hjust = 1, vjust = 1, angle = 45), 
        panel.spacing.x = unit(-0, 'cm')) #+ labs(x = "")


pa_legend <- plot_covar_Ulist_fig2(Ulist_gg$`Daylength (14d prior)`, legend = TRUE) + 
  labs(subtitle = "Daylength (14d prior)")
legend <- get_legend(pa_legend) 
```

```{r build figure 2}


ggdraw() +
  theme_oeco + 
  draw_plot(pa01, x = -0.02, y = 0.4, width = 0.1, height = 0.18) +
  draw_plot(pa02, x = -0.02, y = 0.6, width = 0.1, height = 0.18) +
  #draw_plot(pa03, x = -0.02, y = 0.6, width = 0.1, height = 0.18) +
  #draw_plot(pa04, x = 0.1, y = 0.6, width = 0.1, height = 0.18) +
  draw_plot(pa05, x = -0.02, y = 0.8, width = 0.1, height = 0.18) +
  draw_plot(pa06, x = -0.02, y = 0, width = 0.1, height = 0.18) +
  draw_plot(pa07, x = -0.02, y = 0.2, width = 0.1, height = 0.18) +
  #draw_plot(pa08, x = 0.2, y = 0, width = 0.1, height = 0.18) +
  draw_plot(pa09, x = 0.13, y = 0.6, width = 0.1, height = 0.18) +
  draw_plot(pa10, x = 0.13, y = 0.2, width = 0.1, height = 0.18) +
  draw_plot(pa11, x = 0.13, y = 0.4, width = 0.1, height = 0.18) +
  draw_plot(pa12, x = 0.13, y = 0, width = 0.1, height = 0.18) +
  draw_plot(pa13, x = 0.13, y = 0.8, width = 0.1, height = 0.18) +
  draw_plot(f2a, x = 0.3, y = 0.47, width = 0.55, height = 0.53) +
  draw_plot(legend, x = 0.15, y = 0.34, width = 0.1, height = 0.2) +
  draw_plot(f2b, x = 0.85, y = 0.47, width = 0.15, height = 0.53) +
  draw_plot(f2c, x = 0.3, y = 0, width = 0.55, height = 0.47) +
  draw_plot(f2d, x = 0.85, y = 0, width = 0.15, height = 0.47)


```

```{r}
#| eval: false

save_plot(filename = "../manuscript/revision2/Figure_2_recolor_covariance_matrices_and_posterior_weights.svg", plot = last_plot(), base_height = 5.5, base_width = 8)
```

## Table 1

```{r}
gxe_gg <- get_GxE(m_gulf_gr_hyp)
gxe_mg <- get_GxE(m_midw_gr_hyp)
gxe_gamg <- get_GxE(m_gam_gr_hyp)
gxe_gf <- get_GxE(m_gulf_fl_hyp)
gxe_mf <- get_GxE(m_midw_fl_hyp)
gxe_gamf <- get_GxE(m_gam_fl_hyp)
```

```{r}
sites <- readRDS(here("data/sites.rds"))

site_regions <- sites %>% 
  mutate(Region = case_when(manu_site %in% c("SD", "MO", "IL", "MI", "NE") ~ "North",
                            manu_site %in% c("TX1", "TX2", "TX3", "TX4") ~ "Texas",
                                             TRUE ~ "OK")) %>%
  select(manu_site, Region) %>%
  rename("Site" = "manu_site") %>%
  add_row(Site = "M", Region = "North")
names(gxe_gg)
```

Change these to look at S_AP, S_DS, S_2_no; S_1_row and S_1_col separately

```{r}

one_gxe_summary <- function(df, n_cond = 8, n_sep = 2) {
  nsep <- rep(NA, times = n_sep)
  df <- df %>%
    as_tibble(rownames = "Condition_1") %>%
    pivot_longer(cols = 2:(n_cond+1), names_to = "Condition_2", values_to = "Sig") %>%
    separate(Condition_1, into = c(nsep, "Phenotype", "Garden_1"), sep = "_") %>%
    separate(Condition_2, into = c(nsep, NA, "Garden_2"), sep = "_") %>%
    left_join(site_regions, by = c("Garden_1" = "Site")) %>%
    rename("Region_1" = "Region") %>%
    left_join(site_regions, by = c("Garden_2" = "Site")) %>%
    rename("Region_2" = "Region") %>%
    filter(Garden_1 != Garden_2) %>%
    filter(Region_1 != "OK" & Region_2 !="OK") %>%
    group_by(Region_1, Region_2) %>%
    summarise(Total_sig = sum(Sig), .groups = "keep")
  df$Region_comparison <- NA
  for (i in 1:nrow(df)) {
    v <- sort(c(df$Region_1[i], df$Region_2[i]))
    df$Region_comparison[i] <- paste0(v[1], "_", v[2])
  }
  df <- df %>%
    ungroup() %>%
    select(-Region_1, -Region_2) %>%
    group_by(Region_comparison) %>%
    summarise(n = floor(sum(Total_sig)/2))
  return(df)
}
# test output
one_gxe_summary(df = gxe_mf$S_AP, n_cond = 6)

get_gxe_summary <- function(gxe_list, n_cond = 8, n_sep = 2) {
  AP <- one_gxe_summary(gxe_list$S_AP, n_cond = n_cond, n_sep = n_sep) %>%
    rename(Sign = n)
  DS <- one_gxe_summary(gxe_list$S_DS, n_cond = n_cond, n_sep = n_sep) %>%
    rename(Magnitude = n)
  ND <- one_gxe_summary(gxe_list$S_2_no, n_cond = n_cond, n_sep = n_sep) %>%
    rename(None = n)
  gxe_n <- AP %>%
    full_join(DS, by = "Region_comparison") %>%
    full_join(ND, by = "Region_comparison") %>%
    pivot_longer(cols = -Region_comparison, names_to = "Type_of_GxE", 
                 values_to = "n") %>%
    pivot_wider(names_from = "Region_comparison", values_from = "n")
  gxe_frac <- gxe_n %>%
    mutate(North_North = round(North_North/sum(North_North), digits = 3),
           North_Texas = round(North_Texas/sum(North_Texas), digits = 3),
           Texas_Texas = round(Texas_Texas/sum(Texas_Texas), digits = 3))
  return(list(gxe_counts = gxe_n, gxe_fractions = gxe_frac))
}

get_gxe_summary(gxe_gg) 
```

```{r}
fig3_gg <- get_gxe_summary(gxe_gg) 
fig3_mg <- get_gxe_summary(gxe_mg, n_cond = 7) 
fig3_bg <- get_gxe_summary(gxe_gamg, n_sep = 4) 
print("flowering")
fig3_gf <- get_gxe_summary(gxe_gf) 
fig3_mf <- get_gxe_summary(gxe_mf, n_cond = 6) 
fig3_bf <- get_gxe_summary(gxe_gamf, n_sep = 4) 
```

```{r}
fig3_fractions <- fig3_gg$gxe_fractions |> 
  mutate(Phenotype = "Greenup Date",
         Population = "Gulf") |> 
  full_join(fig3_mg$gxe_fractions) |> 
  mutate(Phenotype = case_when(is.na(Phenotype) ~ "Greenup Date",
                               TRUE ~ Phenotype),
         Population = case_when(is.na(Population) ~ "Midwest",
                               TRUE ~ Population),
         ) |> 
  full_join(fig3_bg$gxe_fractions) |> 
  mutate(Phenotype = case_when(is.na(Phenotype) ~ "Greenup Date",
                               TRUE ~ Phenotype),
         Population = case_when(is.na(Population) ~ "Both",
                               TRUE ~ Population),
         ) |> 
  full_join(fig3_gf$gxe_fractions) |> 
  mutate(Phenotype = case_when(is.na(Phenotype) ~ "Flowering Date",
                               TRUE ~ Phenotype),
         Population = case_when(is.na(Population) ~ "Gulf",
                               TRUE ~ Population),
         ) |> 
  full_join(fig3_mf$gxe_fractions) |> 
  mutate(Phenotype = case_when(is.na(Phenotype) ~ "Flowering Date",
                               TRUE ~ Phenotype),
         Population = case_when(is.na(Population) ~ "Midwest",
                               TRUE ~ Population),
         ) |> 
  full_join(fig3_bf$gxe_fractions) |> 
  mutate(Phenotype = case_when(is.na(Phenotype) ~ "Flowering Date",
                               TRUE ~ Phenotype),
         Population = case_when(is.na(Population) ~ "Both",
                               TRUE ~ Population),
         )
```

```{r}
fig3_fractions <- fig3_fractions |> 
  rename(`North vs North` = North_North,
         `North vs Texas` = North_Texas,
         `Texas vs Texas` = Texas_Texas) |> 
  pivot_longer(cols = `North vs North`:`Texas vs Texas`, names_to = "Regions", values_to = "Fraction of Effects with this GxE Type")

fig3_fractions$Type_of_GxE <- factor(fig3_fractions$Type_of_GxE, levels = c("Sign", "Magnitude", "None"))
fig3_fractions$Phenotype <- factor(fig3_fractions$Phenotype, 
                                   levels = c("Greenup Date", "Flowering Date"))
fig3_fractions$Population <- factor(fig3_fractions$Population, 
                                     levels = c("Gulf", "Midwest", "Both"))
fig3_frac_plot <- fig3_fractions |> 
  ggplot(aes(x = Regions, y = `Fraction of Effects with this GxE Type`)) + 
  geom_bar(aes(fill = Type_of_GxE), position = "stack", stat = "identity", color = "black") + 
  facet_grid(Phenotype ~ Population) +
  scale_fill_manual(values = c("#440154FF", "#5DC863FF",
                                  "white")) +
  theme(legend.position = "top",
        panel.spacing.x = unit(0.1, "mm"), 
        axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))

```

```{r}
#| eval: false

ggdraw() +
  theme_oeco +
  draw_plot(fig3_frac_plot, x = 0, y = 0, width = 1, height = .67)
save_plot(filename = "../manuscript/revision2/Figure_3_Fraction_GxE_by_Region.svg", base_height = 6, base_width = 4.5, plot = last_plot())
```

```{r}
p1 <- mash_plot_effects(m_gulf_gr_hyp, n = 1)
p1$ggobject + 
  theme_oeco + 
  coord_flip()

save_plot(filename = "../manuscript/revision2/Figure_3_GxE_Types_Example.svg", base_height = 3, base_width = 2.5, plot = last_plot())
```

## Figure 3

```{r}
pvdiv_plot_cor <- function(corrmatrix, upper = NULL, legend = FALSE){
  U1 <- corrmatrix

  U1 <- as_tibble(U1, rownames = "rowU", .name_repair = "unique") %>%
          pivot_longer(cols = -.data$rowU, names_to = "colU",
                       values_to = "covar") %>%
          filter(!is.na(.data$covar)) %>%
    mutate(rowU = str_remove(rowU, 
                             "Stand_BhatGulf_and_Midwest_")) %>%
    mutate(rowU = str_remove(rowU, "Stand_BhatGulf_")) %>%
    mutate(rowU = str_remove(rowU, "Stand_BhatMidwest_")) %>%
    mutate(rowU = str_remove(rowU, "GR50_")) %>%
    mutate(rowU = str_remove(rowU, "FL50_")) %>%
    mutate(colU = str_remove(colU, 
                             "Stand_BhatGulf_and_Midwest_")) %>%
    mutate(colU = str_remove(colU, "Stand_BhatGulf_")) %>%
    mutate(colU = str_remove(colU, "Stand_BhatMidwest_")) %>%
    mutate(colU = str_remove(colU, "GR50_")) %>%
    mutate(colU = str_remove(colU, "FL50_")) %>%
    mutate(rowU = case_when(grepl("^M$", rowU) ~ "MI",
                            TRUE ~ rowU),
           colU = case_when(grepl("^M$", colU) ~ "MI",
                            TRUE ~ colU),)
  U1$colU <- factor(U1$colU, levels = c("TX1", "TX2", "TX3", "OK", "MO", "NE", "MI", "SD"))
  U1$rowU <- factor(U1$rowU, levels = c("TX1", "TX2", "TX3", "OK", "MO", "NE", "MI", "SD"))
  U1 <- arrange(U1, rowU, colU) %>%
    pivot_wider(names_from = colU, values_from = covar) 
  for(i in 1:nrow(U1)){
    for(j in 2:ncol(U1)){
      if(i <= j-1){
        U1[i, j] <- NA
      }
    }
  }
  U1 <- U1 %>%
    pivot_longer(cols = -.data$rowU, names_to = "colU",
                       values_to = "covar")
  U1$colU <- factor(U1$colU, levels = c("TX1", "TX2", "TX3", "OK", "MO", "NE", "MI", "SD")) 
  if(is.null(upper)){
  upper <- max(U1$covar, na.rm = TRUE)+5
  }
  U1_covar <- U1 %>%
    filter(!is.na(.data$covar)) %>%
    ggplot(aes(x = .data$rowU, y = .data$colU)) +
    switchgrassGWAS::theme_oeco +
    geom_tile(aes(fill = .data$covar)) +
    scale_fill_viridis_c(option = "H", limits = c(0, upper)) +
    #geom_text(aes(label = round(.data$covar, 1)), color = "darkgrey") +
    theme(legend.position = "none",
          axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) +
    xlab("") + ylab("") 
  if(legend == TRUE){
    U1_covar <- U1_covar +
      theme(legend.position = c(0.2, 0.9)) +
      geom_text(aes(label = round(.data$covar, 1)), color = "darkgrey")
  }
  return(U1_covar)
}

```

```{r}
 pvdiv_plot_cor(corrmatrix = gxe_gamf$S_AP, legend = TRUE) + 
  theme_oeco +
  labs(subtitle = " ")
```

```{r}
p3legend <- pvdiv_plot_cor(corrmatrix = gxe_gg$S_AP, legend = TRUE, 
                           upper = 4333) + 
  theme_oeco +
  labs(title = "Gulf", subtitle = "Sign difference")
legend <- get_legend(p3legend)

p3a1 <- pvdiv_plot_cor(corrmatrix = gxe_gg$S_AP, legend = FALSE, 
                       upper = 4333) + 
  theme_oeco +
  labs(subtitle = " ")
p3a2 <- pvdiv_plot_cor(corrmatrix = gxe_gg$S_DS, legend = FALSE, 
                       upper = 4333) + 
  theme_oeco +
  labs(subtitle = " ")
p3a3 <- pvdiv_plot_cor(corrmatrix = gxe_gg$S_2_no, legend = FALSE, 
                       upper = 4333) + 
  theme_oeco +
  labs(subtitle = " ")
p3b1 <- pvdiv_plot_cor(corrmatrix = gxe_mg$S_AP, legend = FALSE, 
                       upper = 4333) + 
  theme_oeco +
  labs(subtitle = "Sign difference")
p3b2 <- pvdiv_plot_cor(corrmatrix = gxe_mg$S_DS, legend = FALSE, 
                       upper = 4333) + 
  theme_oeco +
  labs(subtitle = "Magnitude difference")
p3b3 <- pvdiv_plot_cor(corrmatrix = gxe_mg$S_2_no, legend = FALSE, 
                       upper = 4333) + 
  theme_oeco +
  labs(subtitle = "Not distinguishable")
p3c1 <- pvdiv_plot_cor(corrmatrix = gxe_gamg$S_AP, legend = FALSE, 
                       upper = 4333) + 
  theme_oeco +
  labs(subtitle = " ")
p3c2 <- pvdiv_plot_cor(corrmatrix = gxe_gamg$S_DS, legend = FALSE, 
                       upper = 4333) + 
  theme_oeco +
  labs(subtitle = " ")
p3c3 <- pvdiv_plot_cor(corrmatrix = gxe_gamg$S_2_no, legend = FALSE, 
                       upper = 4333) + 
  theme_oeco +
  labs(subtitle = " ")

p3d1 <- pvdiv_plot_cor(corrmatrix = gxe_gf$S_AP, legend = FALSE, 
                       upper = 4333) + 
  theme_oeco +
  labs(subtitle = " ")
p3d2 <- pvdiv_plot_cor(corrmatrix = gxe_gf$S_DS, legend = FALSE, 
                       upper = 4333) + 
  theme_oeco +
  labs(subtitle = " ")
p3d3 <- pvdiv_plot_cor(corrmatrix = gxe_gf$S_2_no, legend = FALSE, 
                       upper = 4333) + 
  theme_oeco +
  labs(subtitle = " ")
p3e1 <- pvdiv_plot_cor(corrmatrix = gxe_mf$S_AP, legend = FALSE, 
                       upper = 4333) + 
  theme_oeco +
  labs(subtitle = "Sign difference")
p3e2 <- pvdiv_plot_cor(corrmatrix = gxe_mf$S_DS, legend = FALSE, 
                       upper = 4333) + 
  theme_oeco +
  labs(subtitle = "Magnitude difference")
p3e3 <- pvdiv_plot_cor(corrmatrix = gxe_mf$S_2_no, legend = FALSE, 
                       upper = 4333) + 
  theme_oeco +
  labs(subtitle = "Not distinguishable")
p3f1 <- pvdiv_plot_cor(corrmatrix = gxe_gamf$S_AP, legend = FALSE, 
                       upper = 4333) + 
  theme_oeco +
  labs(subtitle = " ")
p3f2 <- pvdiv_plot_cor(corrmatrix = gxe_gamf$S_DS, legend = FALSE, 
                       upper = 4333) + 
  theme_oeco +
  labs(subtitle = " ")
p3f3 <- pvdiv_plot_cor(corrmatrix = gxe_gamf$S_2_no, legend = FALSE, 
                       upper = 4333) + 
  theme_oeco +
  labs(subtitle = " ")
```

```{r build figure 3}
ggdraw() +
  theme_oeco +
  draw_plot(p3a1, x = 0, y = .82, width = 1/3, height = .18) +
  draw_plot(p3a2, x = 0, y = 4/6, width = 1/3, height = .18) +
  draw_plot(p3a3, x = 0, y = .51, width = 1/3, height = .18) +
  draw_plot(p3b1, x = 0.33, y = .82, width = 1/3, height = .18) +
  draw_plot(p3b2, x = 0.33, y = 4/6, width = 1/3, height = .18) +
  draw_plot(p3b3, x = 0.33, y = .51, width = 1/3, height = .18) +
  draw_plot(p3c1, x = 0.66, y = .82, width = 1/3, height = .18) +
  draw_plot(p3c2, x = 0.66, y = 4/6, width = 1/3, height = .18) +
  draw_plot(p3c3, x = 0.66, y = .51, width = 1/3, height = .18) +
  draw_plot(p3d1, x = 0, y = 2/6, width = 1/3, height = .18) +
  draw_plot(p3d2, x = 0, y = 1/6, width = 1/3, height = .18) +
  draw_plot(p3d3, x = 0, y = 0/6, width = 1/3, height = .18) +
  draw_plot(p3e1, x = 0.33, y = 2/6, width = 1/3, height = .18) +
  draw_plot(p3e2, x = 0.33, y = 1/6, width = 1/3, height = .18) +
  draw_plot(p3e3, x = 0.33, y = 0/6, width = 1/3, height = .18) +
  draw_plot(p3f1, x = 0.66, y = 2/6, width = 1/3, height = .18) +
  draw_plot(p3f2, x = 0.66, y = 1/6, width = 1/3, height = .18) +
  draw_plot(p3f3, x = 0.66, y = 0/6, width = 1/3, height = .18) +
  draw_plot(legend, x = 0.37, y = .38, width = 1/3, height = .18)

```

```{r}
#| eval: false

save_plot(filename = "../manuscript/Coauthors/PNAS/Revision/Figure_3_Effect_Types_by_Site.svg", plot = last_plot(), base_height = 10, base_width = 5.5)
```

## Figure 4

2014-03-06: Change margins so entire QTL plots are shown. Panel a: Greenup QTL. Panel b: Flowering QTL. Indicate which QTL have 1% mash tail SNPs within.

Comparison with QTL for the four-way mapping cross for green up (GR50), flowering (FL50), three functions of weather variables for green-up (from Figure 2; Both: Temp Ave, 1d; Both: Daylength change (s) 1d prior; Gulf: Daylength (14d prior), and two functions of weather variables for flowering (from Figure 2: Midwest: day length change (s) 2d prior; Gulf: cumulative rainfall, 7d).

Li ran the QTL analysis 2024-02-14. Here Alice combines the QTL with the mash SNP effects to build the analysis for Figure 4.

It's an open question how to combine these into an informative main text figure.

The full QTL Lod plots for flowering & greenup phenotypes should go in the SI. Here, try plotting just the significant chromosomes, with a QTL above the permutation threshold.

#### Figure 4A

LOD QTL

Adapted from Analysis_v0.7_QTL_interval_lod_plot.Rmd

Make sure to Load mash objects at start of Step 5

```{r}
library(qtl)
library(qtl2)
# library(plyr)
# library(tidyverse)
library(qtl2convert)
#library(cowplot)
```

```{r}
workingdir <- here("phenology-fourway/5-QTLmappingForAlice/")
load(file.path(workingdir, 'cross_reduced_marker_FL50_phenotypes_Alice_7_SITES.RData'))
load(file.path(workingdir, 'scan1Results_FL50_phenotypes_Alice_7_SITES.RData'))

map  =  lapply(pull.map(cross), function(x) x[1,])
###get the threshold value for each model and output the QTL intervals
threshold_full = summary(s1permfull,alpha = 0.05)
threshold_reduced = summary(s1permreduced,alpha = 0.05)
```

```{r}
###  g x e
gxe = s1full - s1reduced
gxe_perm = threshold_full - threshold_reduced ###or gxe_perm = summary(gxe, alpha=0.05)

###get the peak for full model and gxe model
peaks_full = find_peaks(s1full, map, threshold = threshold_full, drop = 1.5, peakdrop = 5)
peaks_gxe = find_peaks(gxe, map, threshold = gxe_perm, drop = 1.5)

flank_marker_full = peaks_full %>% mutate(flank_lo = find_marker(map, chr, ci_lo), flank_hi=find_marker(map, chr, ci_hi))
# write.csv(flank_marker_full,'QTLsWithFlankMarkers_FL50_phenotypes_Alice_7_SITES_Full_model.csv') ###change the name you want

flank_marker_gxe = peaks_gxe %>% mutate(flank_lo = find_marker(map, chr, ci_lo), flank_hi=find_marker(map, chr, ci_hi))
# write.csv(flank_marker_gxe,'QTLsWithFlankMarkers_FL50_phenotypes_Alice_7_SITES_gxe_model.csv')

###########
```

```{r}
get_post_weights <- function(m){
  log10bf_df <- switchgrassGWAS:::get_log10bf(m = m) %>%
      as.data.frame() %>%
      rownames_to_column(var = "value") %>%
      dplyr::mutate(value = as.integer(.data$value)) %>%
      as_tibble() %>%
      left_join(switchgrassGWAS:::get_marker_df(m = m), by = "value") %>%
      dplyr::rename(log10BayesFactor = .data$V1) %>%
      dplyr::select(-.data$value)
  
  pw_df <- as_tibble(m$posterior_weights)
  pw_df <- switchgrassGWAS:::get_marker_df(m = m) %>%
    bind_cols(pw_df)
  
  ggman_df <- pw_df %>%
    #left_join(m_meta) %>%
    tidyr::separate(.data$Marker, into = c("Chr", "Pos"), remove = FALSE, sep = "_",
             extra = "merge", convert = TRUE) %>%
    left_join(log10bf_df, by = "Marker") %>%
    dplyr::arrange(.data$Chr, .data$Pos) 
  return(ggman_df)
}

pw_gg <- get_post_weights(m_gulf_gr_hyp)
pw_gf <- get_post_weights(m_gulf_fl_hyp) %>%
  mutate(Subpop = "Gulf")

pw_mg <- get_post_weights(m_midw_gr_hyp)
pw_mf <- get_post_weights(m_midw_fl_hyp) %>%
  mutate(Subpop = "Midwest")

pw_gamg <- get_post_weights(m_gam_gr_hyp)
pw_gamf <- get_post_weights(m_gam_fl_hyp) %>%
  mutate(Subpop = "Both")
```

Decide on cutoff to use for rug plots and enrichment analysis: SNPs sig in 1% tail or BF\>2, whichever is stricter

1% tail is stricter in all cases except Midwest flowering, where BF\>2 is stricter, equivalent to a 0.49% tail (0.995119 quantile).

What is the Bayes Factor at the 99th quantile? If it's not above 2, what is the quantile where the BF \> 2?

```{r}
quantile(pw_gf$log10BayesFactor, 0.99)  # Gulf: Use 2.56 BF
quantile(pw_mf$log10BayesFactor, 0.99)  # Midwest: Use 2 BF
quantile(pw_gamf$log10BayesFactor, 0.99)  # GAM: Use 2.65 BF
quantile(pw_mf$log10BayesFactor, 0.995119)

quantile(pw_gg$log10BayesFactor, 0.99)  # Gulf: Use 2.0989 BF
quantile(pw_mg$log10BayesFactor, 0.99)  # Midwest: Use 4.6831 BF
quantile(pw_gamg$log10BayesFactor, 0.99)  # GAM: Use 3.0865 BF
```

```{r}
rug_gf <- pw_gf %>%
  filter(log10BayesFactor > 2.559618) %>% 
  mutate(Pos = Pos/1000000, 
         LOD = -0.5)
rug_gamf <- pw_gamf %>%
  filter(log10BayesFactor > 2.64938) %>% 
  mutate(Pos = Pos/1000000, 
         LOD = -0.5)
rug_mf <- pw_mf %>%
  filter(log10BayesFactor > 2) %>% 
  mutate(Pos = Pos/1000000, 
         LOD = -0.5)

rug_gg <- pw_gg %>%
  filter(log10BayesFactor > 2.0989) %>% 
  mutate(Pos = Pos/1000000, 
         LOD = -0.5)
rug_gamg <- pw_gamg %>%
  filter(log10BayesFactor > 3.0865) %>% 
  mutate(Pos = Pos/1000000, 
         LOD = -0.5)
rug_mg <- pw_mg %>%
  filter(log10BayesFactor > 4.6831) %>% 
  mutate(Pos = Pos/1000000, 
         LOD = -0.5)
```

```{r}
threshold_df <- threshold_full %>% 
  as_tibble(rownames = "Threshold") %>%
  pivot_longer(GR50:crain_7d, names_to = "Phenotype", values_to = "LOD") %>%
  mutate(Phe = case_when(Phenotype %in% c("GR50", "tave_1d", "dyln_14d_prior",
                                          "dyln_change_sec") ~ "greenup",
                         Phenotype %in% c("FL50", "dyln_change_sec_2d_prior",
                                          "crain_7d") ~ "flowering", 
                         TRUE ~ NA_character_),
         Phenotype_key = case_when(Phenotype == "GR50" ~ 
                                     "Greenup Date",
                                   Phenotype == "tave_1d" ~ 
                                     "Temp Ave, 1d",
                                   Phenotype == "dyln_14d_prior" ~ 
                                     "Daylength (14d prior)",
                                   Phenotype == "dyln_change_sec" ~ 
                                     "Daylength change (s)",
                                   Phenotype == "FL50" ~
                                     "Flowering Date",
                                   Phenotype == "dyln_change_sec_2d_prior" ~
                                     "Daylength change (s), 2d prior",
                                   Phenotype == "crain_7d" ~ 
                                     "Cumulative rainfall, 7d",
                                   TRUE ~ NA_character_)) 

fig4b <- s1full %>%
  as_tibble(rownames = "Marker") %>%
  pivot_longer(GR50:crain_7d, names_to = "Phenotype", values_to = "LOD") %>%
  filter(Phenotype %in% c("FL50", "dyln_change_sec_2d_prior", "crain_7d")) %>% 
  separate(Marker, into = c("Chr", "Pos"), sep = "_", remove = FALSE, 
           convert = TRUE) %>%
  mutate(Phenotype_key = case_when(Phenotype == "GR50" ~ 
                                     "Greenup Date",
                                   Phenotype == "tave_1d" ~ 
                                     "Temp Ave, 1d",
                                   Phenotype == "dyln_14d_prior" ~ 
                                     "Daylength (14d prior)",
                                   Phenotype == "dyln_change_sec" ~ 
                                     "Daylength change (s)",
                                   Phenotype == "FL50" ~
                                     "Flowering Date",
                                   Phenotype == "dyln_change_sec_2d_prior" ~
                                     "Daylength change (s), 2d prior",
                                   Phenotype == "crain_7d" ~ 
                                     "Cumulative rainfall, 7d",
                                   TRUE ~ NA_character_)) |> 
  filter(!grepl("loc", Chr)) %>%
  ggplot(aes(x = Pos, y = LOD)) + 
  geom_line(aes(color = Phenotype_key)) +
  geom_rug(data = rug_gamf, sides = "t", alpha = 0.1) + 
  geom_rug(data = rug_gf, sides = "b", alpha = 0.2) + 
  geom_rug(data = rug_mf, outside = TRUE, sides = "b", alpha = 0.2) + 
  geom_hline(data = filter(threshold_df, 
                           Phenotype_key %in% c("Flowering Date", 
                                                "Daylength change (s), 2d prior",
                                                "Cumulative rainfall, 7d")),
             aes(yintercept = LOD, color = Phenotype_key, linetype = Phenotype_key)) +
  facet_wrap(~Chr, nrow = 2, scales = "free_x") +
  theme_oeco +
  scale_color_manual(values = c("#000099", "#CC0066", "darkgrey", "#000666")) + 
  scale_linetype_manual(values = c(4,4,4,4,4)) +
  theme(legend.position = "top",
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.spacing.x = unit(0.1, "mm"),
        text = element_text(size = 10, face="bold"),
        strip.text = element_text(size = 10, face="bold"),
        axis.title = element_text(size = 10,face="bold"),
        axis.text.x = element_text(size = 10, angle = 45, hjust = 1, vjust = 1),
        ) + 
  xlab("Position (Mb)") + ylab("LOD score") +
  scale_x_continuous(breaks = c(0, 20, 40, 60, 80)) + 
  coord_cartesian(clip = "off")
save_plot(filename = "../manuscript/revision2/Figure_4_FL50_QTL_by_lod_score_w_rugs.svg", base_height = 6, base_width = 6.5, plot = last_plot())
```

```{r}
fig4a <- s1full |> 
  as_tibble(rownames = "Marker") %>%
  pivot_longer(GR50:crain_7d, names_to = "Phenotype", values_to = "LOD") %>%
  filter(Phenotype %in% c("GR50", "tave_1d", "dyln_14d_prior", 
                          "dyln_change_sec")) %>% 
  mutate(Phenotype_key = case_when(Phenotype == "GR50" ~ 
                                     "Greenup Date",
                                   Phenotype == "tave_1d" ~ 
                                     "Temp Ave, 1d",
                                   Phenotype == "dyln_14d_prior" ~ 
                                     "Daylength (14d prior)",
                                   Phenotype == "dyln_change_sec" ~ 
                                     "Daylength change (s)",
                                   TRUE ~ NA_character_)) |> 
  separate(Marker, into = c("Chr", "Pos"), sep = "_", remove = FALSE, 
           convert = TRUE) %>%
  filter(!grepl("loc", Chr)) %>%
  ggplot(aes(x = Pos, y = LOD)) + 
  geom_line(aes(color = Phenotype_key)) +
  geom_rug(data = rug_gamg, sides = "t", alpha = 0.1) + 
  geom_rug(data = rug_gg, sides = "b", alpha = 0.2) + 
  geom_rug(data = rug_mg, outside = TRUE, sides = "b", alpha = 0.2) + 
  geom_hline(data = filter(threshold_df, 
                           Phenotype_key %in% c("Greenup Date", "Temp Ave, 1d",
                                            "Daylength (14d prior)", 
                                            "Daylength change (s)")), 
             aes(yintercept = LOD, color = Phenotype_key, 
                 linetype = Phenotype_key)) +
  facet_wrap(~Chr, nrow = 2, scales = "free_x") +
  theme_oeco +
  scale_color_manual(values = c("#006600", "#FFCC00",  "grey", "darkorange",
                                "#000666")) + 
  scale_linetype_manual(values = c(4,4,4,4,4,4)) +
  theme(legend.position = "top",
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.spacing.x = unit(0.1, "mm"),
        text = element_text(size = 10, face="bold"),
        strip.text = element_text(size = 10, face="bold"),
        axis.title = element_text(size = 10,face="bold"),
        axis.text.x = element_text(size = 10, angle = 45, hjust = 1, vjust = 1),
        ) + 
  xlab("Position (Mb)") + ylab("LOD score") +
  scale_x_continuous(breaks = c(0, 20, 40, 60, 80)) + 
  coord_cartesian(clip = "off")
save_plot(filename = "../manuscript/revision2/Figure_4_GR50_QTL_by_lod_score_w_rugs.svg", base_height = 6, base_width = 6.5, plot = last_plot())
```

#### Figure 4B

Same SVG line drawing that was used previously. Description of the two mapping panels used.

#### Figure 4C

Enrichment analysis

Adapted from Analysis_v0.6_QTL_GxE_and_mash_comparison.Rmd

Prepare the QTL dataframe

```{r}
qtldf <- read_csv(here("phenology-fourway/5-QTLmappingForAlice/QTLsWithFlankMarkers_FL50_phenotypes_Alice_7_SITES_Full_model.csv"))

qtldf <- qtldf %>%
  separate(flank_lo, into = c("CHR", "Pos_Mb_lo"), sep = "_", 
           convert = TRUE) %>%
  separate(flank_hi, into = c("flank", "Pos_Mb_hi"), sep = "_", 
           convert = TRUE) %>%
  mutate(Pos_Mb_lo = round(Pos_Mb_lo, digits = 2),
         Pos_Mb_hi = round(Pos_Mb_hi, digits = 2)) %>%
  dplyr::select(CHR, Pos_Mb_lo, Pos_Mb_hi, lodcolumn, lod, everything()) %>%
  arrange(CHR, Pos_Mb_lo)

qtlplot <- qtldf %>%
  mutate(phe = case_when(lodcolumn == "FL50" ~ "flowering",
                              lodcolumn == "dyln_change_sec_2d_prior" ~
                           "daylength change (s) 2d prior",
                              lodcolumn == "dyln_change_sec" ~ 
                           "daylength change (s) 1d prior",
                              lodcolumn == "GR50" ~ "greenup",
                              lodcolumn == "crain_gr2fl" ~ 
                           "Rainfall, GR to FL")) %>%
  #filter(phe %in% c("Daylength", "GDD, GR to FL")) %>%
  mutate(POS_lo = Pos_Mb_lo * 1000000,
         POS_hi = Pos_Mb_hi * 1000000)

qtlplot$phe <- factor(qtlplot$phe, 
                      levels = c("flowering", "daylength change (s) 2d prior",
                                 "GDD, GR to FL", "Daylength",
                                          "daylength change (s)",
                                          "Rainfall, 1 day",
                                                  #"Rainfall, 2d sum",
                                                  "Rainfall, 3d sum",
                                                  "Rainfall, 5d sum"#,
                                                  #"Rainfall, 7d sum"
                                                  ))

qtlplot_fl <- qtlplot %>% 
  filter(lodcolumn %in% c("FL50", "dyln_change_sec_2d_prior")) 
qtlplot_gr <- qtlplot %>% 
  filter(lodcolumn %in% c("GR50", "dyln_change_sec")) 
```

Function to compute hypergeometric test for each row in a QTL df

```{r}

get_QTL_enrichment <- function(m, qtl_df, quantile = 0.99){
  pw_df_all <- get_post_weights(m)
  # do not filter for unique LOD intervals for the random QTL intervals 
  # do this by not having lod in the random QTL intervals
  if("lod" %in% colnames(qtl_df)) {
    qtl_df <- qtl_df %>%
      arrange(desc(lod)) %>%
      mutate(pos = as.integer(pos)) %>%
      group_by(CHR, pos) %>%
      dplyr::slice(1) %>%
      arrange(CHR, pos)
  }
  
  BFthresh <- quantile(pw_df_all$log10BayesFactor, quantile)
  pw_df <- pw_df_all %>%
    filter(log10BayesFactor > BFthresh) %>%
    dplyr::select(Chr:Pos, log10BayesFactor, everything())
  
  for(i in 1:nrow(qtl_df)){  # from 1 to 16
  ## In block & > 2
  QTLandBF <- pw_df %>%
    filter(Chr %in% qtl_df$CHR[i] & between(Pos, qtl_df$POS_lo[i],
                                             qtl_df$POS_hi[i])) %>% 
    tally()
  ## BF>2
  inBF <- pw_df %>%
    tally()
  ## BF not > 2 (all minus BF > 2, all is below)
  allwrtBF <- pw_df_all %>%
    tally()
  ## All in block
  inQTL <- pw_df_all %>%
    filter(Chr %in% qtl_df$CHR[i] & between(Pos, qtl_df$POS_lo[i],
                                             qtl_df$POS_hi[i])) %>%
    tally()
  notinBF <- (allwrtBF$n[1]-inBF$n[1])
  pval <- phyper(QTLandBF$n[1], inBF$n[1], allwrtBF$n[1]-inBF$n[1], 
                 inQTL$n[1], lower.tail = FALSE)
  
  if(i == 1){
  outputdf <- tibble(Chr = qtl_df$CHR[i], Pos_lo = qtl_df$POS_lo[i], 
                     Pos_hi = qtl_df$POS_hi[i], inQTLandBF = QTLandBF$n[1], 
                     inBF = inBF$n[1], notinBF = notinBF, 
                     inQTL = inQTL$n[1], pvalue = pval)
  } else {
    outputdf <- outputdf %>%
      add_row(Chr = qtl_df$CHR[i], Pos_lo = qtl_df$POS_lo[i], 
              Pos_hi = qtl_df$POS_hi[i],inQTLandBF = QTLandBF$n[1], 
              inBF = inBF$n[1], notinBF = notinBF, 
              inQTL = inQTL$n[1], 
              pvalue = pval)
    }
  }
  return(outputdf)
}

```

```{r}
enrich_gf <- get_QTL_enrichment(m_gulf_fl_hyp, qtl_df = qtlplot_fl, 0.99) %>%
  mutate(subpop = "Gulf", phenotype = "flowering")
enrich_mf <- get_QTL_enrichment(m_midw_fl_hyp, qtl_df = qtlplot_fl, 0.995119) %>%
  mutate(subpop = "Midwest", phenotype = "flowering")
enrich_gamf <- get_QTL_enrichment(m_gam_fl_hyp, qtl_df = qtlplot_fl, 0.99) %>%
  mutate(subpop = "Both", phenotype = "flowering")


enrich_df <- enrich_gf %>%
  full_join(enrich_mf) %>%
  full_join(enrich_gamf) %>%
  arrange(Chr, Pos_lo)
enrich_df <- enrich_df %>%
  left_join(qtlplot_fl, by = c("Chr" = "CHR", "Pos_lo" = "POS_lo", "Pos_hi" = "POS_hi")) %>%
  dplyr::select(Chr, Pos_lo, Pos_hi, inQTLandBF:subpop, lod, lodcolumn, pos) %>%
  unique() %>%
  arrange(Chr, Pos_lo, lodcolumn)

enrich_df %>%
  filter(pvalue < 0.05)
fl_enrichd <- enrich_df %>%
  filter(inQTLandBF > 0) |> 
  arrange(Chr, Pos_lo, lodcolumn) |> 
  distinct(Chr, Pos_lo, subpop, .keep_all = TRUE)
  
# t.test(enrich_df[enrich_df$pvalue < 0.05,]$lod, enrich_df[enrich_df$pvalue >= 0.05,]$lod) 
qtlplot_fl %>% group_by(CHR, POS_lo) %>% tally()
# 10 unique QTL by Pos lo/hi. 5 of 10 have enriched mash hits.
```

```{r}
fl_enrichd |> 
  write_csv(here("data", "Enriched_flowering_QTL.csv"))
fl_labels <- read_csv(here("data", "Enriched_flowering_QTL_labels.csv"))


fig_4b <- fig4b +
  geom_text_repel(data = fl_labels, aes(x = pos, y = lod, label = subpop), nudge_y = 2)
library(ggrepel)
```

```{r}
enrich_gg <- get_QTL_enrichment(m_gulf_gr_hyp, qtl_df = qtlplot_gr, 0.99) %>%
  mutate(subpop = "Gulf", phenotype = "greenup")
enrich_mg <- get_QTL_enrichment(m_midw_gr_hyp, qtl_df = qtlplot_gr, 0.99) %>%
  mutate(subpop = "Midwest", phenotype = "greenup")
enrich_gamg <- get_QTL_enrichment(m_gam_gr_hyp, qtl_df = qtlplot_gr, 0.99) %>%
  mutate(subpop = "Both", phenotype = "greenup")

enrich_gr <- enrich_gg %>%
  full_join(enrich_mg) %>%
  full_join(enrich_gamg) %>%
  arrange(Chr, Pos_lo)
enrich_gr <- enrich_gr %>%
  left_join(qtlplot_gr, by = c("Chr" = "CHR", "Pos_lo" = "POS_lo", "Pos_hi" = "POS_hi")) %>%
  dplyr::select(Chr, Pos_lo, Pos_hi, inQTLandBF:subpop, lod, lodcolumn, pos) %>%
  unique() %>%
  arrange(Chr, Pos_lo, lodcolumn)

enrich_gr  # 0 of 3 unique QTL have enriched mash hits for green-up.
enrich_gr |> write_csv(file = here("data", "Enriched_greenup_QTL.csv"))
```

```{r}
gr_labels <- read_csv(here("data", "Enriched_greenup_QTL_labels.csv"))


fig_4a <- fig4a +
  geom_text_repel(data = gr_labels, aes(x = pos, y = lod, label = subpop), nudge_y = 2)
library(ggrepel)
```

```{r}
ggdraw() + 
  theme_oeco +
  draw_plot(fig_4a, x = 0, y = 0.5, width = 1, height = .5) +
  draw_plot(fig_4b, x = 0, y = 0, width = 1, height = .5)
  
save_plot(filename = "../manuscript/revision2/Figure_4_QTL_Overlaps.svg", base_height = 9, base_width = 6.5, plot = last_plot())
```

```{r}
#| eval: false


pw_3f_all <- pw_gf %>%
  full_join(pw_mf) %>%
  full_join(pw_gamf) %>%
  arrange(Chr, Pos) 

sig_random <- c()
chr_size_mash <- pw_3f_all %>%
  ungroup() %>%
  group_by(Chr) %>%
  dplyr::summarise(Pos_lo = min(Pos),
                   Pos_hi = max(Pos))
j = 1
for(j in 1:1000){
  qtl_size <- qtlplot_fl %>%
    dplyr::select(CHR, POS_lo, POS_hi) %>%
    dplyr::distinct() %>%   # don't doublecount completely overlapping QTL
    #(does doublecount partially overlapping QTL, however.)
    group_by(CHR, POS_lo) %>%
    dplyr::mutate(Size = POS_hi - POS_lo) %>%
    dplyr::select(CHR, POS_lo, Size)

  rchr <- chr_size_mash$Chr[sample(1:18, nrow(qtl_size), replace = TRUE)]
  rposlo <- c()
  for(i in 1:length(rchr)){
    rposlo[i] <- sample(chr_size_mash$Pos_lo[which(chr_size_mash$Chr == rchr[i])]:chr_size_mash$Pos_hi[which(chr_size_mash$Chr == rchr[i])], 1)
  }
  
  random_qtl <- tibble(CHR = rchr, POS_lo = rposlo, Size = qtl_size$Size) %>%
    mutate(POS_hi = POS_lo + Size) %>%
    arrange(CHR, POS_lo)

  random_gf <- get_QTL_enrichment(m = m_gulf_fl_hyp, qtl_df = random_qtl, 0.99) %>%
    mutate(subpop = "Gulf", phenotype = "flowering")
  random_mf <- get_QTL_enrichment(m_midw_fl_hyp, qtl_df = random_qtl, 0.995119) %>%
    mutate(subpop = "Midwest", phenotype = "flowering")
  random_gamf <- get_QTL_enrichment(m_gam_fl_hyp, qtl_df = random_qtl, 0.99) %>%
    mutate(subpop = "Both", phenotype = "flowering")
  
  random_df <- random_gf %>%
    full_join(random_mf) %>%
    full_join(random_gamf) %>%
    arrange(Chr, Pos_lo)

  sig_random[j] <- nrow(filter(random_df, pvalue < 0.05))
}
saveRDS(sig_random, file = "../data/Random_QTL_df_FL50_significant_enrichments_of_mash_1per_tail_or_mash_BF2_tail_SNPs_1000runs.rds")


```

```{r}
sig_random <- readRDS(file = here( "data/Random_QTL_df_FL50_significant_enrichments_of_mash_1per_tail_or_mash_BF2_tail_SNPs_1000runs.rds"))


tibble(`mash 1% tail significant enrichments` = sig_random) %>%
  ggplot(aes(x = `mash 1% tail significant enrichments` )) +
  theme_oeco +
  geom_histogram(binwidth = 1) + 
  xlim(c(1, 24)) + ylab("") +
  geom_vline(xintercept = 5, linetype = 2, color = "red")
save_plot(filename = "../manuscript/revision2/Figure_4_QTL_overlaps_random_QTL_enrichments_with_mash_1000runs.png", plot = last_plot(), base_height = 1.8, base_asp = 1.8)
```
